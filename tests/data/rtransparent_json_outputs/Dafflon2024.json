[
  {
    "article": "Dafflon2024",
    "pmid": "Dafflon2024.xml",
    "is_coi_pred": false,
    "coi_text": "",
    "is_funded_pred": true,
    "funding_text": "<TEI xmlns=\"http://www.teic.org/ns/1.0\"><teiHeader><fileDesc><titleStmt><title level=\"a\" type=\"main\" coords=\"1,84.09,72.12,427.10,30.56\">Reliability and predictability of phenotype information from functional connectivity in large imaging datasets<\/title><\/titleStmt><sourceDesc><biblStruct><analytic><author><persName coords=\"1,77.97,127.75,77.89,8.74\"><forename type=\"first\" coords=\"1,77.97,127.75,29.58,8.74\">Jessica<\/forename><surname coords=\"1,110.87,127.75,31.42,8.74\">Dafflon<\/surname><note type=\"marker\">1<\/note><note type=\"marker_delimiter\">,<\/note><note type=\"marker\">2<\/note><note type=\"O\" coords=\"1,153.10,127.75,2.77,8.74\">,<\/note><\/persName><affiliation coords=\"1,113.68,159.50,367.91,9.63\" key=\"aff0\"><note type=\"raw_affiliation\"><label><hi rend=\"superscript\">1<\/hi><\/label> Data Science &amp; Sharing Team, National Institute of Mental Health, Bethesda, MD, USA<\/note><note type=\"marker\" coords=\"1,113.68,159.50,3.65,5.24\"><hi rend=\"superscript\">1<\/hi><\/note><orgName type=\"institution\" coords=\"1,122.44,161.26,248.37,7.86\">Data Science &amp; Sharing Team, National Institute of Mental Health<\/orgName><note type=\"O\" coords=\"1,391.84,161.26,4.21,7.86\">,<\/note><note type=\"O\" coords=\"1,434.10,161.26,4.37,7.86\">,<\/note><note type=\"O\" coords=\"1,453.56,161.26,6.01,7.86\">,<\/note><address><settlement coords=\"1,399.12,161.26,4.37,7.86\">Bethesda<\/settlement><region coords=\"1,441.54,161.26,6.01,7.86\">MD<\/region><country coords=\"1,462.65,161.26,18.94,7.86\">USA<\/country><\/address><\/affiliation><affiliation coords=\"1,125.58,170.46,344.10,9.63\" key=\"aff1\"><note type=\"raw_affiliation\"><label><hi rend=\"superscript\">2<\/hi><\/label> Machine Learning Team, National Institute of Mental Health, Bethesda, MD, USA<\/note><note type=\"marker\" coords=\"1,125.58,170.46,3.65,5.24\"><hi rend=\"superscript\">2<\/hi><\/note><orgName type=\"institution\" coords=\"1,134.34,172.22,224.56,7.86\">Machine Learning Team, National Institute of Mental Health<\/orgName><note type=\"O\" coords=\"1,379.94,172.22,4.21,7.86\">,<\/note><note type=\"O\" coords=\"1,422.19,172.22,4.37,7.86\">,<\/note><note type=\"O\" coords=\"1,441.67,172.22,6.01,7.86\">,<\/note><address><settlement coords=\"1,387.21,172.22,4.37,7.86\">Bethesda<\/settlement><region coords=\"1,429.64,172.22,6.01,7.86\">MD<\/region><country coords=\"1,450.75,172.22,18.94,7.86\">USA<\/country><\/address><\/affiliation><\/author><author><persName coords=\"1,159.18,127.75,95.24,8.74\"><forename type=\"first\" coords=\"1,159.18,127.75,29.25,8.74\">Dustin<\/forename><surname coords=\"1,191.76,127.75,55.43,8.74\">Moraczewski<\/surname><note type=\"marker\">1<\/note><note type=\"O\" coords=\"1,251.66,127.75,2.77,8.74\">,<\/note><\/persName><affiliation coords=\"1,113.68,159.50,367.91,9.63\" key=\"aff0\"><note type=\"raw_affiliation\"><label><hi rend=\"superscript\">1<\/hi><\/label> Data Science &amp; Sharing Team, National Institute of Mental Health, Bethesda, MD, USA<\/note><note type=\"marker\" coords=\"1,113.68,159.50,3.65,5.24\"><hi rend=\"superscript\">1<\/hi><\/note><orgName type=\"institution\" coords=\"1,122.44,161.26,248.37,7.86\">Data Science &amp; Sharing Team, National Institute of Mental Health<\/orgName><note type=\"O\" coords=\"1,391.84,161.26,4.21,7.86\">,<\/note><note type=\"O\" coords=\"1,434.10,161.26,4.37,7.86\">,<\/note><note type=\"O\" coords=\"1,453.56,161.26,6.01,7.86\">,<\/note><address><settlement coords=\"1,399.12,161.26,4.37,7.86\">Bethesda<\/settlement><region coords=\"1,441.54,161.26,6.01,7.86\">MD<\/region><country coords=\"1,462.65,161.26,18.94,7.86\">USA<\/country><\/address><\/affiliation><\/author><author><persName coords=\"1,257.74,127.75,46.87,8.74\"><forename type=\"first\" coords=\"1,257.74,127.75,17.88,8.74\">Eric<\/forename><surname coords=\"1,278.95,127.75,18.43,8.74\">Earl<\/surname><note type=\"marker\">1<\/note><note type=\"O\" coords=\"1,301.84,127.75,2.77,8.74\">,<\/note><\/persName><affiliation coords=\"1,113.68,159.50,367.91,9.63\" key=\"aff0\"><note type=\"raw_affiliation\"><label><hi rend=\"superscript\">1<\/hi><\/label> Data Science &amp; Sharing Team, National Institute of Mental Health, Bethesda, MD, USA<\/note><note type=\"marker\" coords=\"1,113.68,159.50,3.65,5.24\"><hi rend=\"superscript\">1<\/hi><\/note><orgName type=\"institution\" coords=\"1,122.44,161.26,248.37,7.86\">Data Science &amp; Sharing Team, National Institute of Mental Health<\/orgName><note type=\"O\" coords=\"1,391.84,161.26,4.21,7.86\">,<\/note><note type=\"O\" coords=\"1,434.10,161.26,4.37,7.86\">,<\/note><note type=\"O\" coords=\"1,453.56,161.26,6.01,7.86\">,<\/note><address><settlement coords=\"1,399.12,161.26,4.37,7.86\">Bethesda<\/settlement><region coords=\"1,441.54,161.26,6.01,7.86\">MD<\/region><country coords=\"1,462.65,161.26,18.94,7.86\">USA<\/country><\/address><\/affiliation><\/author><author><persName coords=\"1,307.93,127.75,83.81,8.74\"><forename type=\"first\" coords=\"1,307.93,127.75,26.15,8.74\">Dylan<\/forename><forename type=\"middle\" coords=\"1,337.41,127.75,5.95,8.74\">M<\/forename><note type=\"O\" coords=\"1,343.36,127.75,5.95,8.74\">.<\/note><surname coords=\"1,352.63,127.75,31.88,8.74\">Nielson<\/surname><note type=\"marker\">2<\/note><note type=\"O\" coords=\"1,388.98,127.75,2.77,8.74\">,<\/note><\/persName><affiliation coords=\"1,125.58,170.46,344.10,9.63\" key=\"aff1\"><note type=\"raw_affiliation\"><label><hi rend=\"superscript\">2<\/hi><\/label> Machine Learning Team, National Institute of Mental Health, Bethesda, MD, USA<\/note><note type=\"marker\" coords=\"1,125.58,170.46,3.65,5.24\"><hi rend=\"superscript\">2<\/hi><\/note><orgName type=\"institution\" coords=\"1,134.34,172.22,224.56,7.86\">Machine Learning Team, National Institute of Mental Health<\/orgName><note type=\"O\" coords=\"1,379.94,172.22,4.21,7.86\">,<\/note><note type=\"O\" coords=\"1,422.19,172.22,4.37,7.86\">,<\/note><note type=\"O\" coords=\"1,441.67,172.22,6.01,7.86\">,<\/note><address><settlement coords=\"1,387.21,172.22,4.37,7.86\">Bethesda<\/settlement><region coords=\"1,429.64,172.22,6.01,7.86\">MD<\/region><country coords=\"1,450.75,172.22,18.94,7.86\">USA<\/country><\/address><\/affiliation><\/author><author><persName coords=\"1,395.06,127.75,87.48,8.74\"><forename type=\"first\" coords=\"1,395.06,127.75,32.20,8.74\">Gabriel<\/forename><surname coords=\"1,430.59,127.75,44.71,8.74\">Loewinger<\/surname><note type=\"marker\">2<\/note><note type=\"O\" coords=\"1,479.77,127.75,2.77,8.74\">,<\/note><\/persName><affiliation coords=\"1,125.58,170.46,344.10,9.63\" key=\"aff1\"><note type=\"raw_affiliation\"><label><hi rend=\"superscript\">2<\/hi><\/label> Machine Learning Team, National Institute of Mental Health, Bethesda, MD, USA<\/note><note type=\"marker\" coords=\"1,125.58,170.46,3.65,5.24\"><hi rend=\"superscript\">2<\/hi><\/note><orgName type=\"institution\" coords=\"1,134.34,172.22,224.56,7.86\">Machine Learning Team, National Institute of Mental Health<\/orgName><note type=\"O\" coords=\"1,379.94,172.22,4.21,7.86\">,<\/note><note type=\"O\" coords=\"1,422.19,172.22,4.37,7.86\">,<\/note><note type=\"O\" coords=\"1,441.67,172.22,6.01,7.86\">,<\/note><address><settlement coords=\"1,387.21,172.22,4.37,7.86\">Bethesda<\/settlement><region coords=\"1,429.64,172.22,6.01,7.86\">MD<\/region><country coords=\"1,450.75,172.22,18.94,7.86\">USA<\/country><\/address><\/affiliation><\/author><author><persName coords=\"1,179.82,127.75,337.49,20.69\"><forename type=\"first\" coords=\"1,485.86,127.75,31.44,8.74\">Patrick<\/forename><surname coords=\"1,179.82,139.71,37.39,8.74\">Mcclure<\/surname><note type=\"marker\">3<\/note><note type=\"O\" coords=\"1,221.67,139.71,2.77,8.74\">,<\/note><\/persName><affiliation coords=\"1,195.75,181.42,203.78,9.63\" key=\"aff2\"><note type=\"raw_affiliation\"><label><hi rend=\"superscript\">3<\/hi><\/label> Naval Postgraduate School, Monterey, CA, USA<\/note><note type=\"marker\" coords=\"1,195.75,181.42,3.65,5.24\"><hi rend=\"superscript\">3<\/hi><\/note><orgName type=\"institution\" coords=\"1,204.50,183.18,86.21,7.86\">Naval Postgraduate School<\/orgName><note type=\"O\" coords=\"1,311.20,183.18,47.13,7.86\">, Monterey,<\/note><note type=\"O\" coords=\"1,372.15,183.18,5.38,7.86\">,<\/note><address><region coords=\"1,361.40,183.18,5.38,7.86\">CA<\/region><country coords=\"1,380.59,183.18,18.94,7.86\">USA<\/country><\/address><\/affiliation><\/author><author><persName coords=\"1,227.76,139.71,105.05,8.74\"><forename type=\"first\" coords=\"1,227.76,139.71,26.29,8.74\">Adam<\/forename><forename type=\"middle\" coords=\"1,257.38,139.71,5.29,8.74\">G<\/forename><note type=\"O\" coords=\"1,262.67,139.71,5.29,8.74\">.<\/note><surname coords=\"1,271.28,139.71,34.92,8.74\">Thomas<\/surname><note type=\"marker\">1<\/note><note type=\"O\" coords=\"1,310.67,139.71,22.14,8.74\">, and<\/note><\/persName><affiliation coords=\"1,113.68,159.50,367.91,9.63\" key=\"aff0\"><note type=\"raw_affiliation\"><label><hi rend=\"superscript\">1<\/hi><\/label> Data Science &amp; Sharing Team, National Institute of Mental Health, Bethesda, MD, USA<\/note><note type=\"marker\" coords=\"1,113.68,159.50,3.65,5.24\"><hi rend=\"superscript\">1<\/hi><\/note><orgName type=\"institution\" coords=\"1,122.44,161.26,248.37,7.86\">Data Science &amp; Sharing Team, National Institute of Mental Health<\/orgName><note type=\"O\" coords=\"1,391.84,161.26,4.21,7.86\">,<\/note><note type=\"O\" coords=\"1,434.10,161.26,4.37,7.86\">,<\/note><note type=\"O\" coords=\"1,453.56,161.26,6.01,7.86\">,<\/note><address><settlement coords=\"1,399.12,161.26,4.37,7.86\">Bethesda<\/settlement><region coords=\"1,441.54,161.26,6.01,7.86\">MD<\/region><country coords=\"1,462.65,161.26,18.94,7.86\">USA<\/country><\/address><\/affiliation><\/author><author><persName coords=\"1,336.14,139.71,74.86,8.74\"><forename type=\"first\" coords=\"1,336.14,139.71,40.62,8.74\">Francisco<\/forename><surname coords=\"1,380.08,139.71,30.91,8.74\">Pereira<\/surname><\/persName><\/author><\/analytic><\/biblStruct><\/sourceDesc><\/fileDesc><profileDesc><abstract><p coords=\"1,100.35,224.20,394.59,194.16\">One of the central objectives of contemporary neuroimaging research is to create pre- dictive models that can disentangle the connection between patterns of functional connectivity across the entire brain and various behavioral traits. Previous studies have shown that models trained to predict behavioral features from the individual's functional connectivity have modest to poor performance. In this study, we trained models that predict observable individual traits (phenotypes) and their corresponding singular value decomposition (SVD) representations - herein referred to as latent phenotypes from resting state functional connectivity. For this task, we pre- dicted phenotypes in two large neuroimaging datasets: the Human Connectome Project (HCP) and the Philadelphia Neurodevelopmental Cohort (PNC). We illustrate the importance of regressing out confounds, which could significantly influence phenotype prediction. Our findings reveal that both phenotypes and their corresponding latent phenotypes yield similar predictive performance. Interestingly, only the first five latent phenotypes were reliably identified, and using just these reliable phenotypes for predicting phenotypes yielded a similar performance to using all latent phe- notypes. This suggests that the predictable information is present in the first latent phenotypes, allowing the remainder to be filtered out without any harm in performance. This study sheds light on the intricate relationship between functional connectivity and the predictability and reliability of phenotypic information, with potential implications for enhancing predictive modeling in the realm of neuroimaging research.<\/p><\/abstract><\/profileDesc><note type=\"&lt;PAD&gt;\" coords=\"1,410.99,138.13,3.97,6.12\"><hi rend=\"superscript\">2<\/hi><\/note><\/teiHeader><text><body><div><head coords=\"1,72.00,474.58,94.19,10.52\" n=\"1\">Introduction<\/head><p coords=\"1,500.58,583.70,8.86,8.74\">One of the central objectives of contemporary neuroscience is to elucidate a connection between brain structure/function and behavior. This connection could provide clinically relevant metrics, and be used for prognosis and treatment decisions. In order to identify such connections, many neuroimaging studies have focused on predicting observable characteristics or behavior - broadly, phenotypes - from brain measurements. Despite the popularity of this question, most studies report a small correlation of r = 0.1−0.4 between the phenotypes and their predictions from brain measurements; moreover, the prediction performance for similar or related phenotype measures may vary substantially across studies, (<ref type=\"bibr\" target=\"#b34\" coords=\"1,72.00,571.75,451.28,20.69\">Greene and Constable, 2023<\/ref>; <ref type=\"bibr\" target=\"#b71\" coords=\"1,166.70,583.70,49.93,8.74\">Sui et al., 2020<\/ref>; <ref type=\"bibr\" target=\"#b3\" coords=\"1,238.10,583.70,74.16,8.74\">Poldrack et al., 2020<\/ref>; <ref type=\"bibr\" target=\"#b57\" coords=\"1,333.74,583.70,67.79,8.74\">Pervaiz et al., 2020<\/ref>; <ref type=\"bibr\" target=\"#b27\" coords=\"1,423.02,583.70,64.27,8.74\">Genon et al., 2022<\/ref>).<\/p><p coords=\"1,372.25,739.15,8.86,8.74\">The situation described above can be attributed to several factors, for instance intrinsic variations of scanning equipment, noise at various stages of acquisition, or natural and pathological differences between study participants, among others. Moreover, the effect of these factors can be exacerbated by variations in sample size across studies. In general, the use of machine learning methods in typical clinical neuroimaging datasets is severely constrained by their size (tens to low hundreds of subjects), in comparison with their dimensionality (tens of thousands of features). Determining how much data is needed to train models to predict brainbehavior associations is still an open question. Recent research by <ref type=\"bibr\" target=\"#b9\" coords=\"1,72.00,667.42,451.28,20.69\">Marek et al. (2022)<\/ref> suggested that at least a thousand subjects are needed to accurately measure univariate brain- behavior associations, and that small studies fail to replicate and produce inflated effect sizes. This controversial study prompted an avalanche of responses showing that the brainbehavior relationships could be predicted from smaller datasets by using multivariate models and holdout samples (<ref type=\"bibr\" target=\"#b70\" coords=\"1,72.00,715.24,451.27,20.69\">Spisak et al., 2023<\/ref>) and thoughtfully choosing the brain data and behavioral targets of prediction (<ref type=\"bibr\" target=\"#b8\" coords=\"1,72.00,727.19,451.28,20.69\">Cecchetti and Handjaras, 2022<\/ref>; <ref type=\"bibr\" target=\"#b33\" coords=\"1,167.84,739.15,71.05,8.74\">Gratton et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b22\" coords=\"1,260.36,739.15,98.60,8.74\">Rosenberg and Finn, 2022<\/ref>).<\/p><p coords=\"2,72.00,87.11,451.28,44.60\">In addition, recent studies (<ref type=\"bibr\" target=\"#b54\" coords=\"1,207.15,751.13,77.51,8.74\">Nikolaidis et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b26\" coords=\"1,305.75,751.13,52.94,8.74\">Gell et al., 2023<\/ref>) argue that increasing sample size might improve the prediction performance, but not be sufficient for consistent results. They argue that arXiv:2405.00255v1 [qbio.NC] 1 May 2024 the reliability of the prediction targets will limit predictive performance, and that the reliability of clinical and cognitive phenotypes should be better assessed. In particular, <ref type=\"bibr\" target=\"#b54\" coords=\"2,355.80,87.11,97.00,8.74\">Nikolaidis et al. (2022)<\/ref> showcased that, while inconsistency in results is aggravated by small sample sizes, the use of more reliable measures can allow for more robust estimates. The authors' suggested solution to improve reliability is to aggregate across multiple raters and/or measurements.<\/p><p coords=\"2,284.08,399.61,8.86,8.74\">Traditionally, brainbehavior models have primarily focused on individual behaviors or symptoms examined in isolation. The increasing recognition of the integrated nature of the brain has led to a methodological shift, however, and researchers have begun to consider the complex interplay of variables across various demographic, clinical, and behavioral phenotypes (<ref type=\"bibr\" target=\"#b10\" coords=\"2,360.32,172.46,95.91,8.74\">Holmes and Patrick, 2018<\/ref>). Following this line of thought, <ref type=\"bibr\" target=\"#b9\" coords=\"2,161.61,184.41,60.25,8.74\">Chen et al. (2023<\/ref>, <ref type=\"bibr\" coords=\"2,242.85,184.41,4.76,8.74\">2022<\/ref>) averaged the scores of selected behavioral phenotypes into three categories (Cognition, Personality, and Mental Health). Their main idea was that the combination would reflect not only a single phenotypic measure and its noise, but a hopefully more robust combination of many measures. In addition, because scores across different behavioral tasks may be correlated, many studies process them using dimensionality reduction techniques like factor analysis (<ref type=\"bibr\" target=\"#b9\" coords=\"2,451.21,232.23,53.90,8.74\">Ooi et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b66\" coords=\"2,72.00,244.19,75.73,8.74\">Schöttner et al., 2023<\/ref>) and principal component analysis (<ref type=\"bibr\" target=\"#b11\" coords=\"2,320.55,244.19,64.45,8.74\">Chopra et al., 2022<\/ref>). The goal of dimensionality reduction is to find a reduced set of (potentially orthogonal) latent variables that contain most of the information contained in the original phenotypes. <ref type=\"bibr\" target=\"#b9\" coords=\"2,286.12,268.10,69.51,8.74\">Ooi et al. (2022)<\/ref> showed that latent phenotypes derived from factor analysis were more predictable than the original phenotypes in the HCP and ABCD datasets. Therefore, in this study, we attempted to replicate this finding in a different dataset using a different dimensionality reduction algorithm: singular value decomposition (SVD). We chose to use SVD because it produces the optimal lowrank approximation to the data, in addition to having other desirable properties that will be discussed later in this paper. In addition, <ref type=\"bibr\" target=\"#b9\" coords=\"2,298.28,327.87,68.77,8.74\">Ooi et al. (2022)<\/ref> only used the top three components. Therefore, an additional question that was left unanswered, and we address in this paper, is what is the impact of using all latent phenotypes and if the latter might be more reliable than the former, and hence lead to better predictive results. This is particularly relevant as prior research has identified a limited set of latent phenotypes that connect brain imaging data with a wide array of phenotypes, including cognition, mental health, demographic characteristics, and clinical phenotypes (<ref type=\"bibr\" target=\"#b9\" coords=\"2,419.48,387.65,56.56,8.74\">Chen et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b3\" coords=\"2,72.00,387.65,451.28,20.69\">Smith et al., 2015<\/ref>; <ref type=\"bibr\" target=\"#b32\" coords=\"2,126.24,399.61,61.34,8.74\">Goyal et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b52\" coords=\"2,209.06,399.61,61.74,8.74\">Miller et al., 2016<\/ref>).<\/p><p coords=\"2,72.00,532.77,451.28,104.38\">An additional motivation for this work is analyzing the robustness of findings in the literature when using a different dimensionality reduction method and applying this dimensionality reduction to more than one dataset. There is an inherent flexibility in the process of designing and executing scientific experiments and, in particular, analytical pipelines, and this can be yet another source of variability in the performance of brainbehavior prediction models. It is now widely acknowledged that a single research question can be approached through a diverse array of analytical pipelines, often resulting in different outcomes (<ref type=\"bibr\" target=\"#b14\" coords=\"2,119.82,484.95,65.82,8.74\">Dafflon et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b6\" coords=\"2,206.74,484.95,100.44,8.74\">Botvinik-Nezer et al., 2020<\/ref>; <ref type=\"bibr\" target=\"#b7\" coords=\"2,328.27,484.95,31.76,8.74\">Carp, 2012<\/ref>). In young research areas, such as functional neuroimaging, in which many of the ground truths are yet to be discovered, there are limited foundations to favor one option over its alternatives. As a result, researchers must consider various factors when designing imaging analyses, including data preprocessing, feature selection, functional connectivity computation, and prediction model of choice. A study by <ref type=\"bibr\" target=\"#b57\" coords=\"2,329.52,532.77,89.77,8.74\">Pervaiz et al. (2020)<\/ref> explored the impact of various choices on model performance, provided insights into the influence of these choices, and offered recommendations about which parcellations to use, metrics for estimating functional connectivity and how those choices depend on the target of interest. It's worth noting, however, that while this study employed a substantial sample size, it primarily focused on a limited set of cognitive measures (fluid intelligence and neuroticism score), age, and sex. Consequently, whether the findings and suggestions generalize to other phenotypes remains uncertain. Many studies individually focused on one dataset or one phenotype prediction, and the absence of a gold standard complicates comparisons between studies that adopt different analytical approaches.<\/p><p coords=\"2,72.00,642.02,451.27,56.56\">In this study, we examined the questions above in the context of predicting rich phenotypic infor- mation from functional connectivity data, in the Human Connectome Project (HCP) and Philadelphia Neurodevelopmental Cohort (PNC) datasets. First, we analyzed the importance of regressing out con- founding <hi rend=\"superscript\">1<\/hi> covariates such as age or sex at birth, since predictive performance for variables correlated with these may be inflated by the known predictability of age and sex from functional connectivity.<\/p><p coords=\"2,230.99,715.41,292.28,8.74;3,72.00,75.16,451.28,20.69\">We then attempted to replicate previous findings that latent phenotypes are more predictable than original phenotypes (<ref type=\"bibr\" target=\"#b9\" coords=\"2,166.01,715.41,51.70,8.74\">Ooi et al., 2022<\/ref>). Specifically, we compared the performance of models predicting latent phenotypes from functional connectivity to the performance of models predicting the original phenotypes from functional connectivity.<\/p><p coords=\"3,72.00,99.12,451.28,104.38\">Since the reliability of the predicted variable limits the maximal observable predictive performance, we also evaluated the reliability of the latent phenotypes across different participant samples, and the re- lationship between reliability and predictability from functional connectivity. Finally, we tested whether the phenotype information predictable from functional connectivity is primarily contained in reliable latent phenotypes. To this effect, we reconstructed phenotypes from the subset of reliable latent vari- ables, and evaluated the performance of models trained to predict these reconstructed phenotypes from functional connectivity. Overall, our study provides insights into the relationship between prediction ac- curacy and reliability and extends our understanding of the extent to which latent, and reconstructed phenotypes can be predicted from resting state fMRI.<\/p><\/div><div><head coords=\"3,72.00,225.50,71.64,10.52\" n=\"2\">Methods<\/head><\/div><div><head coords=\"3,72.00,251.04,69.22,8.77\" n=\"2.1\">Datasets<\/head><p coords=\"3,72.00,319.07,451.28,68.51\">In the analyses described in this paper, we used resting state fMRI data and phenotype information from two datasets: the Human Connectome project (<ref type=\"bibr\" target=\"#b3\" coords=\"3,281.17,283.20,80.06,8.74\">Van Essen et al., 2012<\/ref>) and Philadelphia Neurodevelop- mental Cohort (<ref type=\"bibr\" target=\"#b26\" coords=\"3,142.75,295.16,93.42,8.74\">Satterthwaite et al., 2016<\/ref>). We will focus on predicting phenotypes only from functional connectivity (FC) measures derived from the fMRI data, as prediction models derived from FC outper- form other modalities in general (<ref type=\"bibr\" target=\"#b9\" coords=\"3,222.22,319.07,51.64,8.74\">Ooi et al., 2022<\/ref>). We provide datasetspecific details in the following subsections, and describe the common extraction of FC matrix after that. The code used for the anal- ysis, together with a list of all subjects used for training, validation, and holdout, can be found at the following repo: https://github.com/JessyD/bblocksphenotypes. Our work relies on the recently released \"datasetphenotypes\" tool <hi rend=\"superscript\">4<\/hi> , which outputs BIDS tabular phenotypic data dictionaries and transforms tabular phenotypic data to BIDS TSVs for common neuroimaging datasets.<\/p><\/div><div><head coords=\"3,72.00,408.96,178.26,8.77\">Human Connectome Project (HCP)<\/head><p coords=\"3,72.00,432.90,451.28,44.60\">We used the behavioral and imaging data from the HCP Young Adult 1200 Subject release (<ref type=\"bibr\" target=\"#b3\" coords=\"3,200.41,420.95,109.62,8.74\">Van Essen et al., 2012<\/ref>)(N=1071 ; 485 males/586 females aged 28.8 ± 3.7 years). As described by <ref type=\"bibr\" target=\"#b3\" coords=\"3,179.80,432.90,82.73,8.74\">Barch et al. (2013)<\/ref>, the functional connectivity data was acquired with a 32- channel head coil on a 3T Simens Skyra with TR=720 s, TE=33.1 ms, flip angle=52 deg, BW=2290 Hz/Px, inplane FOV=208 × 180 mm, 72 slices, 2.0 mm isotropic voxels, with a multiband acceleration factor of 8.<\/p><p coords=\"3,72.00,480.77,451.28,128.29\">Subjects were chosen if their imaging preprocessing pipeline was completed without error. While for PNC, we removed frames that were considered as highmotion using their framewise displacement and DVARS (as described below), we did not use quality control metrics to select HCP subjects. Subjects were split into a training set (N=856; 385 males/471 females aged 28.88 ± 3.70 years), a validation set (N=108; 45 males/63 females aged 28.16 ± 3.50 years), and a separate holdout set (N=107; 55 males/52 females aged 28.69 ± 3.96). The holdout set was not used for the results reported in this paper, and is being kept for a future preregistered analysis. Subjects were assigned to the training, validation, and holdout sets in a twostage procedure. First, all families with two or more siblings were included in the training set. This was done to prevent leakage of information between twins or other siblings, which could happen if they were split between training and the other two datasets. Second, all subjects were assigned at random to the three datasets, until the specified number of participants was obtained in each.<\/p><\/div><div><head coords=\"3,72.00,624.50,59.11,8.74\">Imaging Data<\/head><p coords=\"3,72.00,636.45,451.28,20.69\">We used the cleaned version of the HCP S1200 release, and used the grayordinate resting- state functional MRI data processed with ICA-FIX and MSM-All provided by <ref type=\"bibr\" target=\"#b3\" coords=\"3,418.41,636.45,91.98,8.74\">Glasser et al. (2013a)<\/ref>, a pipeline which was developed and optimized for this dataset.<\/p><\/div><div><head coords=\"3,72.00,672.57,97.20,8.74\">Behavioral Phenotypes<\/head><p coords=\"4,72.00,134.93,451.28,44.60\">We used 83 phenotypes scores (Appendix A1 includes a full list of all scores used), which span across behavioral domains of cognition and personality and some additional variables that we included to be consistent with prior work. To facilitate comparisons, we included all behavioral measures previously used by <ref type=\"bibr\" target=\"#b9\" coords=\"3,156.07,708.44,70.17,8.74\">Ooi et al. (2022)<\/ref>, <ref type=\"bibr\" target=\"#b31\" coords=\"3,233.85,708.44,79.50,8.74\">Kong et al. (2019)<\/ref> and <ref type=\"bibr\" target=\"#b38\" coords=\"3,335.92,708.44,66.57,8.74\">He et al. (2020)<\/ref>. All behavioral scores were individually zscored across participants, and outliers that were above and below 3 standard deviations were treated as missing data as described below. We incorporated behavioral phenotypes categorized as \"ageadjusted behaviors\", which had undergone prior age adjustments by the HCP team, alongside the raw, unadjusted behaviors. The difference between \"ageadjusted behaviors\" and \"unadjusted\" behavior is that, while the Unadjusted Scale Score evaluates a participant's performance compared to the entire NIH Toolbox Normative Sample, the Age-Adjusted Scale Score assesses a participant's performance in the context of a specific age group within the Toolbox Norming Sample (e.g., 18-29 or 30-35) (<ref type=\"bibr\" target=\"#b68\" coords=\"4,72.00,111.02,451.28,20.69\">Slotkin et al., 2012<\/ref>). Both the outliers and the missing data were imputed using the IterativeImputer function from scikitlearn (<ref type=\"bibr\" target=\"#b0\" coords=\"4,166.50,134.93,78.93,8.74\">Pedregosa et al., 2011<\/ref>), which models each feature as a function of other features, and uses the model to predict its missing values, iterating over features in a roundrobin fashion. To make sure that we keep the development and validation sets completely separate, we trained the imputation function on the development set and applied it to the validation set.<\/p><\/div><div><head coords=\"4,72.00,200.16,249.38,8.77\">Philadelphia Neurodevelopmental Cohort (PNC)<\/head><p coords=\"4,72.00,200.19,451.28,92.42\">As described by <ref type=\"bibr\" target=\"#b26\" coords=\"4,402.75,200.19,116.17,8.74\">Satterthwaite et al. (2016)<\/ref>, the PNC dataset was acquired using a 3T Siemens TIM Trio, with a 32-channel head coil with TR=3000 ms, TE=32 ms, flip angle=90 deg, BW=2056, FOV=192 x 192 mm, voxel resolution of 3x3x3mm with 46 slices. For our analysis, we used 1082 subjects. Similar to the HCP dataset, we split the subjects into a development set (N=864; 404 males/460 females aged 15.670 ± 3.376 years), validation set (N=109; 48 males / 61 females aged 16.231 ± 3.364), and an unused holdout (N=109, 47 males/ 62 females aged 15.97 ± 3.38) dataset reserved for future preregistered analyses. Subjects were assigned to the training, validation, and holdout sets in the same twostage process used in the HCP data.<\/p><\/div><div><head coords=\"4,72.00,307.29,60.16,8.74\">Imaging Data<\/head><p coords=\"4,72.00,319.25,451.28,80.47\">We preprocessed the PNC dataset using fmriprep version 21.0.2 (<ref type=\"bibr\" target=\"#b18\" coords=\"4,431.63,307.29,72.60,8.74\">Esteban et al., 2019<\/ref>) (additional information about all software used can be found in Appendix A.5.1). For motion censoring, time points were considered individually. If a time point exceeded 0.2 mm framewise displacement or a derivative root mean square (DVARS) above 75, it was marked as a point to be censored. Intervals of less than five points between censor points were also censored. The six estimated headmotion parameters, their derivatives, the average signal within the anatomicallyderived white matter, and cerebrospinal fluid masks obtained from fmriprep were used as nuisance variables and regressed from the fMRI signal before we computed the FC.<\/p><\/div><div><head coords=\"4,72.00,414.39,98.26,8.74\">Behavioral Phenotypes<\/head><p coords=\"4,72.00,438.30,451.27,44.60\">Although the PNC dataset includes surveys, cognitive and clinical phenotypes, for this analysis we did not use surveys or clinical phenotypes. We selected 39 summary scores from cognitive tasks from the PNC dataset (<ref type=\"bibr\" target=\"#b26\" coords=\"4,246.82,438.30,95.49,8.74\">Satterthwaite et al., 2016<\/ref>; <ref type=\"bibr\" target=\"#b36\" coords=\"4,364.21,438.30,54.64,8.74\">Gur et al., 2010<\/ref>; <ref type=\"bibr\" target=\"#b61\" coords=\"4,440.75,438.30,60.38,8.74\">Roalf et al., 2014<\/ref>). See Appendix A. 5.3 for a full list of all scores used. Similar to the procedure used for the HCP dataset, missing values and outliers were imputed using the IterativeImputer function from scikitlearn, and each measure was zscored across participants.<\/p><\/div><div><head coords=\"4,72.00,503.52,276.63,8.77\" n=\"2.2\">Generation of datasets for prediction experiments<\/head><p coords=\"4,487.77,618.62,3.87,8.74\">We constructed functional connectivity matrices by computing the Pearson correlations between the average time series for each pair of brain regions. Regions were defined using the 17-network Schaefer 400 parcellation (<ref type=\"bibr\" target=\"#b31\" coords=\"4,148.17,546.89,70.25,8.74\">Schaefer et al., 2018<\/ref>). If more than one resting state session was available for a subject, we averaged the resulting functional connectivity matrices across sessions and used the resulting one in our analyses. If any of the runs had more than 50% of the runs flagged as time points to be censored, it was excluded from the computation of functional connectivity. Across this paper, we will refer to the data matrix X <hi rend=\"superscript\">n×d<\/hi> ), where n is the number of subjects available and d the number of pairwise connections after vectorizing the lower diagonal (in our case 79800). These pairwise connections will be the input features for the prediction model described in Section 2.5. The process is illustrated in <ref type=\"figure\" target=\"#fig_0\" coords=\"4,452.46,618.62,35.31,8.74\">Figure 1<\/ref>.<\/p><\/div><div><head coords=\"4,72.00,647.99,247.32,8.77\" n=\"2.3\">Dimensionality reduction of phenotype data<\/head><\/div><div><head coords=\"4,72.00,667.41,159.33,8.77\">Linear dimensionality reduction<\/head><p coords=\"4,72.00,667.44,451.28,32.65\">The following paragraphs compare different types of linear dimen- sionality reduction. They introduce those methods and compare them to SVD, the method we used in further analysis.<\/p><p coords=\"5,72.00,273.42,451.28,128.29\">In our experiments, we structure phenotype data as a matrix with n rows (participants) and d columns (phenotype measurements). Each row is therefore a ddimensional observation for a participant. A linear dimensionality reduction method expresses that matrix as a product of a n × k latent variable matrix, and a k × d matrix that expresses observation vectors as a linear combination of latent variables (often called the mixing or loading matrix). The latent variable matrix can be viewed as a reduced dimen- sionality representation of the original matrix. The underlying assumption behind this framing is that each observation does not vary independently in d different ways. Instead, those d measures are driven by one or more latent variables, and that relationship holds across participants. If measurements were the summary scores of different instruments, the latent variables could correspond to factors that drive variance across them; in that case, latent variables would be helpful to elicit relationships between instru- ments. Aside from their role in psychology research, latent variables are potentially useful as prediction targets from imaging, as discussed earlier. This is because they are estimated from multiple phenotype measures they are associated with, and hence, are potentially less noisy. Factorizations can also be used for denoising, in that the product of the latent variable matrix and the mixing matrix can be viewed as an approximation that tries to keep the essential characteristics of the data. This is usually done by considering fewer than the maximum number of latent variables that can be estimated from the data matrix.<\/p><\/div><div><head coords=\"5,72.00,426.26,202.63,8.77\">Linear dimensionality reduction methods<\/head><p coords=\"5,72.00,509.97,451.28,32.65\">There are many linear dimensionality reduction methods. They differ primarily in their assumptions about the relationship between latent variables, and their connection to the measured variables. While it is beyond the scope of this paper to review all the methods available, we briefly do so for those that have been used for experiments similar to those we carry out. Factor Analysis (FA) finds latent variables (factors) and a mixing matrix (loadings) such that between factor correlation is minimized. FA is used in the development of psychometric questionnaires, where the goal is to relate answers to questions to hypothesized latent constructs driving behavior. FA usually includes a step called varimax rotation (<ref type=\"bibr\" target=\"#b46\" coords=\"5,280.47,509.97,37.53,8.74\">Kaiser, 1958<\/ref>), where the goal is to further transform the factor/loading relationship so that each factor loads on as few phenotype measurements as possible, to facilitate interpretability.<\/p><p coords=\"5,72.00,546.52,451.28,44.60\">Independent Component Analysis (ICA) finds latent variables (components) and a mixing matrix such that the factors are statistically independent, not orthogonal, but uncorrelated. Neither FA nor ICA have an intrinsic criterion for choosing the number of dimensions k analogous to the percentage of variance explained in PCA and SVD.<\/p><p coords=\"5,72.00,595.03,451.28,68.51\">Principal Component Analysis (PCA) finds successive orthogonal projection directions of the data that maximize variance after projection. Each latent variable is defined as the projection of all the data points into one dimension; the mixing matrix is derived as part of the process of finding the projection directions. The intuition for this approach is that important latent variables should drive a lot of variance in the observations. Similar to FA, a varimax rotation can also be applied to a PCA to simplify the interpretation of the components.<\/p><p coords=\"5,72.00,763.09,451.28,8.74;6,72.00,75.16,451.28,44.60\">Singular Value Decomposition (SVD), the technique we will use in this paper, finds the same projec- tion directions as PCA if the inputs to the SVD are meancentered. Both PCA and SVD share a useful characteristic that other methods do not have: the percentage of variance explained provides an order of importance of the latent variables. In addition, SVD has a number of practical advantages over PCA (e.g., it does not require computation of a covariance matrix), as well as useful theoretical properties. The one that is most important for this paper is that the data reconstruction through SVD, using k latent variables, is the best rank k approximation of the data, in the least squares sense. We provide an illus- trated introduction to SVD, its mathematical properties, and its relationship with PCA in Section 5.2 of the Appendix. Finally, there are methods such as reduced rank regression that implicitly perform an SVD/PCA of a dataset of target variables, as part of a multivariate, multiple regression model. Given that the results are similar to those obtained by computing an SVD of the target variables, predicting each latent variable independently, and reconstructing predictions of the targets, we do not consider these further.<\/p><\/div><div><head coords=\"6,72.00,141.27,142.37,8.77\" n=\"2.4\">Controlling for age/sex<\/head><p coords=\"6,72.00,161.62,451.28,140.24\">Before training the prediction models we regressed out age and sex at birth terms from each phenotype measure in both datasets: age, sex, sex <hi rend=\"superscript\">2<\/hi> , and the interactions age × sex and age <hi rend=\"superscript\">2<\/hi> × sex. Sex at birth was coded as a 0/1 binary variable and age was zscored. The phenotype measure values used in the prediction experiments were the residual values after fitting this regression model. The purpose of regressing age and sex information out of the phenotype targets was to determine the degree to which their predictability was a combination of a) their being predictable from age/sex (e.g. a developmental phenotype measure) and b) age/sex being predictable from the imaging data. We deliberately did not regress age/sex information out of the imaging data. Our plan is to train neural networks that predict age/sex, in tandem with other phenotypes where age/sex have been regressed out. For that application, age/sex should not be regressed out of the imaging data. As these experiments are meant to produce baseline results using linear models, against which neural network results can be compared, we opted not to regress age/sex out of the imaging data in this case as well.<\/p><p coords=\"6,72.00,305.16,451.28,56.56\">We also conducted a paired twosided ttest to determine if there was a significant difference in performance before and after adjusting for age and sex. Before running the ttest, we calculated the correlations between the actual and predicted values for models both with and without the regression adjustments. We then applied the Fisher ztransformation to these correlations and calculated the average across multiple repetitions.<\/p><\/div><div><head coords=\"6,72.00,383.23,143.04,8.77\" n=\"2.5\">Prediction experiments<\/head><\/div><div><head coords=\"6,72.00,403.57,72.82,8.74\">Prediction model<\/head><p coords=\"6,72.00,427.48,451.28,44.60\">We used a Ridge regression model to find the linear relationship between the imaging data and each of the selected behavioral phenotypes, or the latent variables derived from them. We chose a model with L <hi rend=\"subscript\">2<\/hi> -regularisation, as implemented by the scikitlearn library (<ref type=\"bibr\" target=\"#b0\" coords=\"6,421.38,427.48,79.76,8.74\">Pedregosa et al., 2011<\/ref>), version 1.2.2, as it can handle illposed problems that result from extremely correlated features. The reason for only using a linear prediction model in this work is that our primary goal is to obtain baseline results for future nonlinear models.<\/p><\/div><div><head coords=\"6,72.00,487.65,83.26,8.74\">Experimental setup<\/head><p coords=\"6,72.00,487.65,451.28,176.11\">The predictive results reported reflect the mean and standard deviation - which is an estimate of the standard error of the mean - across 100 bootstrap samples, taking age, gender and family information into account. In this procedure, we first split the training data into a part that would be resampled (80% of the total dataset) and a part that would be used to evaluate the performance of models with different regularization parameters, which was kept fixed (10% of the total dataset). The remaining 10% was kept as a holdout dataset and was not used in this study. We did not use nested crossvalidation. For each resampled training set, we found the optimal setting of the l <hi rend=\"subscript\">2<\/hi> -regularisation term (α) using a grid search over the search space [10 <hi rend=\"superscript\">2<\/hi> , 10 <hi rend=\"superscript\">7<\/hi> ], applying the model to the fixed part of the dataset used for evaluation. The model with the best l <hi rend=\"subscript\">2<\/hi> -regularisation term was then applied to the validation set, yielding one result of the 100 in the sample for predicting that particular phenotype measure. We performed the SVD of the phenotypes within each resampled training set. These were z- scored in a columnwise fashion, i.e., we computed the mean and standard deviation across the training set to normalize that specific phenotype, so that the features with large means or variance would not dominate the results, and repeated this procedure for all phenotypes. We then used the mean and standard deviation from the training dataset to zscore the phenotype measures in the validation set.<\/p><\/div><div><head coords=\"6,72.00,679.32,74.02,8.74\">Model evaluation<\/head><p coords=\"6,72.00,679.32,451.27,44.60\">The performance of each model was evaluated using the coefficient of determination (r <hi rend=\"superscript\">2<\/hi> ) and Pearson's correlation between the predicted measure and the actual measure in the validation set. While Pearson's correlation assumes values between -1 and 1, the r <hi rend=\"superscript\">2<\/hi> can assume values between (−∞, 1] where 1 corresponds to the best possible score, as it is being computed on a separate dataset.<\/p><p coords=\"6,72.00,727.22,451.28,44.60;7,72.00,75.16,451.28,32.65\">We used the Autorank library (<ref type=\"bibr\" target=\"#b40\" coords=\"6,225.51,727.22,44.70,8.74\">Herbold, 2020<\/ref>; <ref type=\"bibr\" target=\"#b16\" coords=\"6,291.60,727.22,43.92,8.74\">Demšar, 2006<\/ref>) to evaluate if there was any statistical difference in the performance of the prediction algorithms using all of the components or a subset thereof. The Autorank library first assesses the normality and heteroscedasticity of the data before selecting the most suitable group level and posthoc test to determine differences between the groups. The familywise significance level for these tests was set at α = 0.05. We provided inputs to the Autorank library by calcu- lating the correlation between the predictions and the actual values, applying the Fisherz transformation to these correlations, and then computing the average correlation across multiple bootstraps.<\/p><\/div><div><head coords=\"7,72.00,127.21,434.58,8.77\" n=\"2.6\">Comparing predictive performance on original phenotypes and latent phenotypes<\/head><p coords=\"7,72.00,145.45,451.28,68.51\">The latent phenotypes are composed of linear combinations of the original phenotypes, so directly com- paring predictive performance between the two is not straightforward. Instead, we computed absolute difference between zscored values of the prediction and true phenotypes (i.e., the error) for the com- ponent with the highest prediction, taking the average over all bootstraps. We also computed the same difference for the best performing latent phenotype. We then used a paired ttest to test the difference in error between the best performing latent phenotype and the best performing original phenotype.<\/p><\/div><div><head coords=\"7,72.00,233.37,213.89,8.77\" n=\"2.7\">Latent phenotypes reliability analysis<\/head><p coords=\"7,72.00,371.16,451.28,116.33\">We conducted analyses to assess the reliability of the latent phenotypes produced by the SVD separately in the HCP and PNC datasets. Specifically, we wanted to determine how similar each latent phenotype would be if the SVD was conducted in distinct sets of subjects with the same phenotypic measures. We accomplished this by combining the training and validation subsets and then randomly splitting these combined datasets into two halves (without replacement) 1000 times. Splits were applied at the family level so that all members of a family were in the same subsample in every splitting. Since the latent phenotypes produced by the SVD are ordered by percent variance explained, the order may differ between samples. To ensure that the order was consistent across all subsample, we first ran an SVD on the combined dataset, saving the latent phenotypes. Then the latent variables from each subsample were reordered to match the order of latent phenotypes in the combined dataset. Components were matched via the Gale-Shapley stable marriage algorithm (<ref type=\"bibr\" target=\"#b25\" coords=\"7,287.30,371.16,86.12,8.74\">Gale and Shapley, 1962<\/ref>) using the correlation between latent phenotype weights as the preferences. Once the latent phenotypes from each subsample within a split were aligned, we took the correlation between the latent phenotype's weights on the features (following the SVD notation, this would be V <hi rend=\"subscript\">T<\/hi> ) as our measure of latent phenotype reliability. In all cases age and sex were regressed out of the phenotypes, values more than three standard deviations from the mean were censored, and missing values were imputed as described above prior to running the SVDs. These preprocessing steps were carried out separately in each subsample. Empirical 95% confidence intervals were determined from the distribution of intersubsample correlations across splits. Correlation coefficients were Fisher ztransformed prior to averaging across splits and then transformed back for plotting/analysis.<\/p><\/div><div><head coords=\"7,72.00,507.53,63.39,10.52\" n=\"3\">Results<\/head><\/div><div><head coords=\"7,72.00,531.09,358.98,8.77\" n=\"3.1\">Predictability of phenotype measures from functional connectivity<\/head><p coords=\"7,72.00,549.33,451.28,20.69\">The goal of this experiment was to ascertain the degree to which each phenotype measure is predictable from functional connectivity, in both HCP and PNC.<\/p><p coords=\"7,72.00,680.84,451.27,20.69\">As described in Section 2.5, we trained ridge regression models to predict each phenotype measure across 100 bootstrap resamplings; we then used them to generate predictions for participants in the validation set, which was fixed rather than resampled. This resampling scheme allows us to estimate the variability in performance across potential training sets for the fixed validation set. We averaged prediction results across resamplings, and used those results to estimate the standard deviation of the mean estimate. <ref type=\"figure\" coords=\"7,139.60,633.02,43.35,8.74\">Figure 2.a<\/ref> and <ref type=\"figure\" target=\"#fig_2\" coords=\"7,204.00,633.02,34.86,8.74\">Figure 3<\/ref>.a show the average correlation between the phenotype predictions and their true values, with the measures sorted by predictability. We can see that for the HCP data the most predictable phenotype is Strength Unadjusted, which measures the Grip Strength (<ref type=\"figure\" coords=\"7,474.36,656.93,36.46,8.74\">Figure 2a<\/ref>). Because of the relation between strength and sex at birth, we repeated the same analysis after regressing out age and sex and their interaction as confounds. Appendix <ref type=\"figure\" target=\"#fig_13\" coords=\"7,345.08,680.84,36.48,8.74\">Figure 8<\/ref> shows the corresponding results using r <hi rend=\"superscript\">2<\/hi> as the metric of performance.<\/p><\/div><div><head coords=\"7,72.00,720.93,441.69,20.72\" n=\"3.2\">Predictability of phenotype measures from functional connectivity after regressing the confounds<\/head><p coords=\"11,411.21,158.84,43.77,8.74\">One of the issues in determining how predictable a phenotype measure is from imaging is the presence of potential confounds, such as participant sex at birth, age, and time of scan, which are to some extent predictable from imaging data. Given this, a phenotype measure might be predictable from imaging data because a) the confound can be predicted from imaging data, and b) the phenotype measure can be predicted from the confound. To try to minimize the impact of confounding variables on our predictions, we regressed out age, sex, and age×sex interaction, as well as their squares, from each phenotypic measure. <ref type=\"figure\" target=\"#fig_3\" coords=\"11,86.94,122.98,36.70,8.74\">Figure 4<\/ref> illustrates the regression beta coefficients for each phenotype measure in HCP (<ref type=\"figure\" coords=\"11,478.42,122.98,35.63,8.74\">Figure 4a<\/ref>) and PNC (<ref type=\"figure\" coords=\"11,121.59,134.93,35.47,8.74\">Figure 4b<\/ref>). The magnitude of the beta coefficient indicates the strength of the relationship between the independent variable and the dependent variable. A list of all the phenotypes used, the acronyms and a short description can be found in <ref type=\"table\" coords=\"11,291.98,158.84,32.38,8.74\">Table 1<\/ref> (HCP) and <ref type=\"table\" coords=\"11,379.57,158.84,31.64,8.74\">Table 5<\/ref>.3 (PNC).<\/p><note type=\"fulltext:other\" coords=\"8,72.85,144.38,449.36,413.39\">0.0 0.2 0.4 0.6 Social_Task_Perc_TOM MeanPurp_Unadj FearAffect_Unadj NEOFAC_N ER40ANG ER40SAD MMSE_Score InstruSupp_Unadj ER40FEAR PainInterf_Tscore LifeSatisf_Unadj Social_Task_Perc_Random ER40_CR AngHostil_Unadj PosAffect_Unadj SelfEff_Unadj Flanker_AgeAdj IWRD_TOT Sadness_Unadj ASR_Anxd_Pct ASR_Soma_T ER40_CRT ASR_Intn_T PSQI_Score Odor_Unadj ProcSpeed_Unadj ProcSpeed_AgeAdj Emotion_Task_Face_Acc PercStress_Unadj Taste_Unadj SCPT_SEN AngAffect_Unadj FearSomat_Unadj ER40NOE ASR_Extn_T Loneliness_Unadj ASR_Intr_T Flanker_Unadj PercReject_Unadj ASR_Witd_T PercHostil_Unadj PMAT24_A_CR Mars_Final ASR_Aggr_T Relational_Task_Acc CogEarlyComp_AgeAdj PicSeq_AgeAdj PicSeq_Unadj NEOFAC_E Language_Task_Story_Avg CogFluidComp_AgeAdj DDisc_AUC_200 NEOFAC_C CardSort_Unadj ASR_Totp_T PicVocab_Unadj CardSort_AgeAdj ASR_Rule_T DDisc_AUC_40K ASR_Thot_T Handedness ListSort_AgeAdj SCPT_SPEC ListSort_Unadj Dexterity_Unadj PicVocab_AgeAdj Friendship_Unadj GaitSpeed_Comp ASR_TAO_Sum VSPLOT_TC NEOFAC_A Language_Task_Math_Avg EmotSupp_Unadj CogTotalComp_AgeAdj NEOFAC_O ReadEng_AgeAdj ReadEng_Unadj CogCrystalComp_AgeAdj AngAggr_Unadj Endurance_Unadj ASR_Attn_T WM_Task_Acc Strength_Unadj a <hi rend=\"subscript\">No Regression<\/hi> 0.0 0.2 0.4 0.6 MeanPurp_Unadj Social_Task_Perc_TOM NEOFAC_N FearAffect_Unadj PainInterf_Tscore MMSE_Score ER40FEAR ER40ANG InstruSupp_Unadj ER40SAD LifeSatisf_Unadj SelfEff_Unadj ER40_CR AngHostil_Unadj PosAffect_Unadj ASR_Extn_T Flanker_AgeAdj Social_Task_Perc_Random Flanker_Unadj Odor_Unadj ASR_Anxd_Pct IWRD_TOT Taste_Unadj ASR_Soma_T ASR_Witd_T ASR_Intn_T ER40_CRT ER40NOE ProcSpeed_AgeAdj PercHostil_Unadj PMAT24_A_CR AngAffect_Unadj PSQI_Score Sadness_Unadj ProcSpeed_Unadj ASR_Intr_T PicSeq_AgeAdj ASR_Totp_T SCPT_SEN ASR_Aggr_T PercStress_Unadj Emotion_Task_Face_Acc PicSeq_Unadj Handedness Language_Task_Story_Avg NEOFAC_C Relational_Task_Acc CogEarlyComp_AgeAdj Loneliness_Unadj PercReject_Unadj ASR_Rule_T Dexterity_Unadj Mars_Final Strength_Unadj FearSomat_Unadj SCPT_SPEC CogFluidComp_AgeAdj VSPLOT_TC ListSort_Unadj CardSort_Unadj ASR_TAO_Sum ASR_Thot_T CardSort_AgeAdj NEOFAC_A ListSort_AgeAdj PicVocab_AgeAdj PicVocab_Unadj EmotSupp_Unadj NEOFAC_E DDisc_AUC_200 DDisc_AUC_40K AngAggr_Unadj Language_Task_Math_Avg CogTotalComp_AgeAdj Friendship_Unadj NEOFAC_O GaitSpeed_Comp ReadEng_AgeAdj CogCrystalComp_AgeAdj ReadEng_Unadj ASR_Attn_T Endurance_Unadj WM_Task_Acc b <hi rend=\"subscript\">With Regression<\/hi> 0.0 0.2 0.4 0.6 MeanPurp_Unadj Social_Task_Perc_TOM NEOFAC_N FearAffect_Unadj PainInterf_Tscore MMSE_Score ER40FEAR ER40ANG InstruSupp_Unadj ER40SAD LifeSatisf_Unadj SelfEff_Unadj ER40_CR AngHostil_Unadj PosAffect_Unadj ASR_Extn_T Flanker_AgeAdj Social_Task_Perc_Random Flanker_Unadj Odor_Unadj ASR_Anxd_Pct IWRD_TOT Taste_Unadj ASR_Soma_T ASR_Witd_T ASR_Intn_T ER40_CRT ER40NOE ProcSpeed_AgeAdj PercHostil_Unadj PMAT24_A_CR AngAffect_Unadj PSQI_Score Sadness_Unadj ProcSpeed_Unadj ASR_Intr_T PicSeq_AgeAdj ASR_Totp_T SCPT_SEN ASR_Aggr_T PercStress_Unadj Emotion_Task_Face_Acc PicSeq_Unadj Handedness Language_Task_Story_Avg NEOFAC_C Relational_Task_Acc CogEarlyComp_AgeAdj Loneliness_Unadj PercReject_Unadj ASR_Rule_T Dexterity_Unadj Mars_Final Strength_Unadj FearSomat_Unadj SCPT_SPEC CogFluidComp_AgeAdj VSPLOT_TC ListSort_Unadj CardSort_Unadj ASR_TAO_Sum ASR_Thot_T CardSort_AgeAdj NEOFAC_A ListSort_AgeAdj PicVocab_AgeAdj PicVocab_Unadj EmotSupp_Unadj NEOFAC_E DDisc_AUC_200 DDisc_AUC_40K AngAggr_Unadj Language_Task_Math_Avg CogTotalComp_AgeAdj Friendship_Unadj NEOFAC_O GaitSpeed_Comp ReadEng_AgeAdj CogCrystalComp_AgeAdj ReadEng_Unadj ASR_Attn_T Endurance_Unadj WM_Task_Acc c <hi rend=\"subscript\">Reconstruction<\/hi> 1 2 3 4 5 all 0.0 0.2 0.4 0.6 d <hi rend=\"subscript\">Latent<\/hi><\/note><note type=\"fulltext:other\" coords=\"9,72.85,166.53,442.50,413.40\">0.2 0.0 0.2 0.4 PADT_T PVRT_RTER MP_MP2RTCR PCPT_T_FPRT PEDT_T PCET_ACC2 PEDT_SAD_PC PLOT_TCRT PEDT_SAME_PC VOLT_SVT PEIT_CR PCET_CAT PWMT_KIWRD_RTC PADT_SAME_PC PEDT_ANG_PC PWMT_KIWRD_TOT VOLT_SVTIRT VOLT_SVTCRT PEDT_HAP_PC PVRT_RTCR PEDT_FEAR_PC PEDT_PC PFMT_IFAC_RTC LNB_MRTC LNB_MCR PEIT_CRT PEDT_A PCPT_T_TPRT PLOT_TC WRAT_CR_STD PADT_A PLOT_PC PFMT_IFAC_TOT PMAT_CR PADT_PC PCPT_T_TP PCPT_T_FP PVRT_CR WRAT_CR_RAW a <hi rend=\"subscript\">No Regression<\/hi> 0.2 0.0 0.2 0.4 PADT_T PADT_SAME_PC MP_MP2RTCR PCET_ACC2 PWMT_KIWRD_RTC PEDT_SAD_PC PCPT_T_FPRT PEDT_T PLOT_TCRT PCPT_T_TPRT PVRT_RTER VOLT_SVT PEDT_ANG_PC PEDT_SAME_PC PEIT_CR PWMT_KIWRD_TOT PCET_CAT PVRT_RTCR PEDT_PC PEIT_CRT PEDT_A VOLT_SVTIRT LNB_MRTC LNB_MCR PEDT_FEAR_PC VOLT_SVTCRT PEDT_HAP_PC PCPT_T_FP PLOT_TC PADT_A PFMT_IFAC_RTC PCPT_T_TP PADT_PC PLOT_PC PFMT_IFAC_TOT WRAT_CR_STD PMAT_CR WRAT_CR_RAW PVRT_CR b <hi rend=\"subscript\">With Regression<\/hi> 0.2 0.0 0.2 0.4 PADT_T PADT_SAME_PC MP_MP2RTCR PCET_ACC2 PWMT_KIWRD_RTC PEDT_SAD_PC PCPT_T_FPRT PEDT_T PLOT_TCRT PCPT_T_TPRT PVRT_RTER VOLT_SVT PEDT_ANG_PC PEDT_SAME_PC PEIT_CR PWMT_KIWRD_TOT PCET_CAT PVRT_RTCR PEDT_PC PEIT_CRT PEDT_A VOLT_SVTIRT LNB_MRTC LNB_MCR PEDT_FEAR_PC VOLT_SVTCRT PEDT_HAP_PC PCPT_T_FP PLOT_TC PADT_A PFMT_IFAC_RTC PCPT_T_TP PADT_PC PLOT_PC PFMT_IFAC_TOT WRAT_CR_STD PMAT_CR WRAT_CR_RAW PVRT_CR c <hi rend=\"subscript\">Reconstruction<\/hi> 1 2 3 4 5 all 0.2 0.0 0.2 0.4 d <hi rend=\"subscript\">Latent<\/hi><\/note><note type=\"fulltext:other\" coords=\"10,240.75,201.11,185.35,8.50\">HCP PNC<\/note><p coords=\"11,72.00,254.49,451.28,32.65\">In the HCP analysis, we did not see a large dependence between the variables and age, and the highest beta coefficient was observed for \"Strength Unadjusted\", where there was a high interaction with sex. This aligns with our expectations as HCP is a young adult cohort while PNC is a neurodevelopmental cohort. Note that we included behavioral phenotypes that had previously been adjusted for age by the HCP team (referred to as \"ageadjusted behaviors\") and the raw unadjusted behaviors. Our initial aim was to compare the beta coefficients between the adjusted and unadjusted variables provided by the HCP consortia. We observed that if we had trained our model without correcting for the confounds, some of the predictive performance would be due to their presence. For the PNC dataset (<ref type=\"figure\" coords=\"11,425.30,254.49,34.55,8.74\">Figure 4b<\/ref>), the highest beta coefficients are observed between age and Total Correct Response for All Test Trials (PEDT A), Median Response Time for All Test Trials (PADT T), and Total Raw Score (WRAT CR RAW).<\/p><p coords=\"11,72.00,290.35,451.28,44.60\">We also compared predictive performance for phenotypes in which we regressed out age and sex confounds or not. Regressing out age and sex results in a significant decrease in mean prediction across all phenotypes (before regression: 0.172 ± 0.143 (mean ± standard deviation); after regression 0.096 ± 0.095; tstatistic:-6.37, value:1.75e-07, df:38)<\/p><\/div><div><head coords=\"11,72.00,354.28,361.40,8.77\" n=\"3.3\">Predictability of SVD latent variables from functional connectivity<\/head><p coords=\"11,72.00,408.31,451.28,80.47\">As described earlier, SVDs were fit to each resampled training set and used to produce latent phenotype scores for that training set and the fixed validation set. Contrary to our expectations, we found that SVD latent phenotypes were not more predictable than individual phenotype measures (correlation in <ref type=\"figure\" coords=\"11,72.00,396.36,451.27,20.69\">Fig- ure 2d<\/ref> and <ref type=\"figure\" coords=\"11,120.03,408.31,35.08,8.74\">Figure 3d<\/ref>; r <hi rend=\"superscript\">2<\/hi> in <ref type=\"figure\" coords=\"11,189.10,408.31,86.04,8.74\">Appendix Figure 8d<\/ref> and <ref type=\"figure\" coords=\"11,296.26,408.31,34.95,8.74\">Figure 9d<\/ref>). We evaluated this by performing a paired ttest to compare the absolute error between predicted and true zscored values for the most predictable latent factor and the most predictable phenotypes. In both datasets the error was not significantly differ- ent between the best phenotype (HCP: phenotype mean error (std):0.890 (0.600)/ PNC: phenotype mean error (std): 0.891 (0.654)) and the best latent phenotype (HCP: latent phenotype mean error (std): 1.001 (0.645) / PNC: latent phenotype mean error (std): 0.950 (0.641); HCP: tstatistic=-1.78, pvalue=0.078, df=107 / PNC: tstatistic=-1.138, pvalue=0.258, df=108).<\/p><note type=\"fulltext:other\" coords=\"11,93.16,516.55,402.64,194.88\">0 20 40 53 60 80 Singular Value index 0.0 0.2 0.4 0.6 0.8 1.0 Explained variance ratio [53] Cumulative explained variance Individual explained variance 0 5 10 15 20 25 30 35 40 Singular Value index 0.0 0.2 0.4 0.6 0.8 1.0 Explained variance ratio [29] Cumulative explained variance Individual explained variance<\/note><\/div><div><head coords=\"12,72.00,75.13,408.34,8.77\" n=\"3.4\">Lowdimensional representations of phenotype variables and their reliability<\/head><p coords=\"12,72.00,110.32,451.28,32.65\">One of our goals was to understand the dependency structure between different phenotype measures, as captured through the SVD of the dataset. This analysis is important to determine if the phenotypes can be represented using a smaller set of uncorrelated latent phenotypes.<\/p><p coords=\"12,72.00,739.17,451.27,32.65\">For both datasets, we can see that while the first two latent phenotypes explain about 30% of the variance, this decays rapidly for successive latent phenotypes (<ref type=\"figure\" target=\"#fig_4\" coords=\"12,341.17,161.19,36.80,8.74\">Figure 5<\/ref>). To attain a comprehensive 95% explanation of the variance, a substantial number of latent phenotypes are required. Considering that each dataset uses a diverse array of tests to cover various cognitive domains, we were not surprised to see that many of the components were required to explain 95% of the variance. We also conducted an experiment to examine the reliability of the latent phenotypes, i.e., how many of them would replicate if the SVD was applied to two independent samples drawn from the same population. To that effect, we simulated this situation with an experiment where we repeatedly split the phenotype dataset into two halves (i.e., subsamples), and independently computed the SVD of each split. To ensure that the order was consistent across all subsample, we first ran an SVD on the combined dataset, saving the latent phenotypes. We then reordered the latent phenotypes in each split to match the order of latent phenotypes in the original dataset based on the Gale-Shapley stable marriage algorithm (<ref type=\"bibr\" target=\"#b25\" coords=\"12,76.77,631.58,85.14,8.74\">Gale and Shapley, 1962<\/ref>) using the correlation between latent phenotype weights as the preferences. The matching procedure was repeated for 1000 random splits of the data. The first five latent phenotypes in each dataset had an intersplit r <hi rend=\"superscript\">2<\/hi> greater than 0.2 in 95% or more or random splits (<ref type=\"figure\" target=\"#fig_5\" coords=\"12,440.65,655.49,34.42,8.74\">Figure 6<\/ref>, <ref type=\"figure\" target=\"#fig_8\" coords=\"12,482.07,655.49,41.20,8.74\">Figure 11<\/ref> in the appendix for correlation). Both datasets also had some reliable lowvariance latent phenotypes (69-73 and 83 in HCP, 35-39 in PNC). Outside of these latent phenotypes, the intersplit correlation of the weights was low. We postulate that this could be due to the loadings for remaining factors being driven by sample idiosyncrasies or the remaining relationships between phenotype measures being weak enough that noise can perturb their estimation. The predictability analysis reveals that the first three HCP latent phenotypes and the fifth HCP latent phenotype, along with the first PNC component, exhibit a correlation mean between true and predicted values that is above 0.15 (<ref type=\"figure\" target=\"#fig_1\" coords=\"12,425.17,739.17,39.52,8.74\">Figures 2<\/ref> and <ref type=\"figure\" coords=\"12,486.95,739.17,3.87,8.74\">3<\/ref>). That predictability decays quickly beyond them with an increase in the prediction performance for a few of the last components that do not explain much variance.<\/p><\/div><div><head coords=\"13,72.00,75.13,432.23,20.72\" n=\"3.5\">Predictability of original phenotypes after training on phenotypes reconstructed from latent space<\/head><p coords=\"13,72.00,107.61,451.28,152.20\">The previous sections investigated the predictability of individual phenotypes measures, and of latent phenotypes derived from them. We saw that only the first five latent phenotypes in each dataset were reliable (the first 5 components explain 40% of the variance in HCP and 45% on PNC), but explaining 95% of the variance would require most of the latent phenotypes (53 on the HCP and 28 in PNC). If we assume that variance explained by unreliable latent phenotypes will not be predictable from functional connectivity data, then these results suggest the intriguing possibility that most of the variance present across phenotype measures might not be predictable from functional connectivity data (at least using linear prediction models in a moderately sized sample of about 1000 subjects for both HCP and PNC). We can test this by comparing the predictive performance of models trained using progressively larger proportions of the variance in the original phenotypes to the performance of models trained on the original phenotypes themselves. If a model trained to predict a reduced variance representation of the phenotypes does as well as models trained with the original phenotypes, then this will indicate that that reduced variance is the maximally predictable portion of the variance.<\/p><p coords=\"13,351.71,358.78,8.03,8.74\">To test this possibility, we took advantage of the fact that the SVD of a dataset can be used to generate the best possible rank k approximation of that dataset, in the least squares sense ( Appendix, section 5.2). This corresponds to reconstructing each phenotype measure by considering only those relationships to all other phenotype measures that explain the most variance. Specifically, we used the first five latent phenotypes, as those were reliability identified (<ref type=\"figure\" target=\"#fig_5\" coords=\"13,277.44,310.96,33.98,8.74\">Figure 6<\/ref>), to produce rank-1 through rank-5 approximate reconstructions of the phenotype measures in each resampling training set. We then evaluated models trained to predict the reconstructed phenotypes against the true, original phenotypes in the validation set. For both datasets, the reconstructed prediction of rank-1 to rank-5 was very similar to that obtained using the original phenotypes. (PNC: <ref type=\"figure\" coords=\"13,237.76,358.78,35.50,8.74\">Figure 3c<\/ref>, HCP: <ref type=\"figure\" coords=\"13,312.24,358.78,35.46,8.74\">Figure 2c<\/ref>).<\/p><p coords=\"13,72.00,430.62,451.28,44.60\">To perform a quantitative comparison between the 5 reconstruction models and the baseline one, we performed a critical difference analysis (<ref type=\"bibr\" target=\"#b16\" coords=\"13,262.17,382.80,42.46,8.74\">Demšar, 2006<\/ref>). This method is used to statistically compare the prediction performance of several models across many different prediction problems (phenotype measures, in this case), to determine which subsets have significant differences in performance relative to other subsets. In the case of HCP data, the posthoc Tukey HSD test revealed a significant decline in performance when employing a single latent phenotype compared to all other groups (<ref type=\"figure\" coords=\"13,470.27,430.62,35.73,8.74\">Figure 12a<\/ref>). Nevertheless, there was no statistically significant difference in performance across all measures when employing 2, 3, 4, 5, or all latent phenotypes. For the PNC dataset, there were no significant differences in performance between utilizing all latent phenotypes and any of the latent phenotypes.<\/p><\/div><div><head coords=\"13,72.00,497.54,81.52,10.52\" n=\"4\">Discussion<\/head><p coords=\"13,175.58,690.79,8.58,8.74\">Phenotype measures are predictable in both HCP and PNC. In this study, we examined prediction of behavioral phenotypes from functional connectivity data. Several studies have trained different kinds of models to predict a variety of phenotype targets, but have mainly focused on one dataset (<ref type=\"bibr\" target=\"#b9\" coords=\"13,72.00,547.33,451.28,20.69\">Chen et al., 2023<\/ref>; <ref type=\"bibr\" target=\"#b5\" coords=\"13,98.56,559.28,107.56,8.74\">Bertolero and Bassett, 2020<\/ref>) or have used PCA with varimax transformation for dimensionality reduction (<ref type=\"bibr\" target=\"#b9\" coords=\"13,121.14,571.24,50.49,8.74\">Ooi et al., 2022<\/ref>). As a first experiment, we tested phenotype prediction from functional con- nectivity in both the Human Connectome Project (HCP) and Philadelphia Neurodevelopmental Cohort (PNC) datasets. We found that phenotypes can be predicted from resting state functional connectivity in both datasets (<ref type=\"figure\" coords=\"13,138.24,607.10,40.90,8.74\">Figure 2b<\/ref> and <ref type=\"figure\" coords=\"13,201.11,607.10,35.38,8.74\">Figure 3b<\/ref>). Similar to other studies, we observed correlations between pre- dicted and true values in the range of 0.1-0.4 for the majority of phenotypes. For example, the top three phenotypes that could be predicted with the highest performance were Working memory score across all memory tasks (WM Task ACC), 2-min walk endurance test (Endurance Unadj), Attention problems (ASR ATTN T) in the HCP (<ref type=\"figure\" coords=\"13,200.64,654.92,34.60,8.74\">Figure 2b<\/ref>) and Professional Verbal Reasoning Test Total Correct Responses for All Test Trials (PVRT CR) Wide Range Achievement Test's Wide Range Assessment Test 4 Total Raw Score (WRAT CR RAW) and Primary Mental Abilities total correct response (PMAT CR) in the PNC dataset (<ref type=\"figure\" coords=\"13,136.27,690.79,35.03,8.74\">Figure 3b<\/ref>).<\/p><\/div><div><head coords=\"13,72.00,715.26,135.08,8.74\">Regression of the confounds is important<\/head><note type=\"fulltext:other\" coords=\"13,243.44,715.26,4.54,8.74\">.<\/note><p coords=\"14,365.70,158.84,8.86,8.74\">Studies predicting phenotypes from imaging data do not always control for demographic confounds in their analyses (<ref type=\"bibr\" target=\"#b12\" coords=\"13,301.37,727.22,70.52,8.74\">Chyzhyk et al., 2022<\/ref>). While this may make sense in some cases (as we discuss below), failure to control for these confounding variables can inflate estimates of how predictable some phenotypes are if those phenotypes are correlated with the demographic confounds. To evaluate the degree to which this could be an issue, we considered the two most common potential confounds: age and sex. We regressed age, sex, age squared and the interactions of age and age squared with sex from our prediction targets - phenotype measures - and evaluated differences in predictive performance. This showed that confounds can inflate the prediction results if not accounted for; this is particularly visible, for instance, in the relation between the phenotypic variable \"strength unadjusted\" and sex in the HCP dataset (r = 0.6 before; r = 0.1 after adjustment; <ref type=\"figure\" coords=\"14,395.42,122.98,42.27,8.74\">Figure 2a<\/ref> and <ref type=\"figure\" coords=\"14,462.13,122.98,36.60,8.74\">Figure 2b<\/ref>). It is also important to note that it is essential to handle confounding separately for the training and test data. Otherwise, attempting to control for these variables across the entire dataset can undermine the independence of the training and testing data (<ref type=\"bibr\" target=\"#b12\" coords=\"14,279.88,158.84,72.54,8.74\">Chyzhyk et al., 2022<\/ref>).<\/p><p coords=\"14,72.00,170.80,451.28,104.38\">Finally, it is worth noting that it may be useful to keep the confounding variables in either the prediction targets or the imaging data, depending on the purpose of the prediction model. One example would be age, which is sometimes regressed out as a confounding variable, and sometimes added as an additional predictor to explain part of the variance. For example, in the context of predicting Alzheimer's disease, not regressing age out of imaging might help prediction models that can consider combinations of age and other features. It is still an open question, and left as an additional researcher's degree of freedom, if the confounds should be removed from the image, targets, or both. In this manuscript, we explored the effects of removing the confounds from the phenotypes but future work should consider regressing the confounds from the images.<\/p><\/div><div><head coords=\"14,72.00,287.62,329.89,8.74\">SVD latent variables are not more predictable than individual phenotype measures<\/head><note type=\"fulltext:other\" coords=\"14,434.67,287.62,4.68,8.74\">.<\/note><p coords=\"14,72.00,287.62,451.28,92.42\">Many of the phe- notype measures collected in large batteries are correlated to some extent. As discussed earlier, dimen- sionality reduction techniques can be applied to transform phenotype measures into a latent variable representation. These variables are usually uncorrelated or independent and, informally, explain different aspects of the phenotype measures. Beyond the scientific reasons for generating them, latent variables may also be cleaner than individual phenotype measures, if the individual measures are taken to be noisy measurements of an underlying construct. And, finally, reducing dimensionality also reduces the number of prediction targets to consider.<\/p><p coords=\"14,72.00,514.76,451.28,68.51\">Several studies have constructed uncorrelated latent variable representations, with each variable ex- plaining different aspects of the phenotypes (<ref type=\"bibr\" target=\"#b66\" coords=\"14,270.03,395.21,77.40,8.74\">Schöttner et al., 2023<\/ref>; <ref type=\"bibr\" target=\"#b9\" coords=\"14,368.97,395.21,51.77,8.74\">Ooi et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b9\" coords=\"14,442.27,395.21,58.86,8.74\">Chen et al., 2022<\/ref>). For example, <ref type=\"bibr\" target=\"#b9\" coords=\"14,130.76,407.17,70.61,8.74\">Ooi et al. (2022)<\/ref> computes a factor analysis of the behavioral scores and predicts the latent phenotypes instead of the raw phenotypes. They observed that latent phenotypes, in particular the first three, are more predictable than using individual measures and that functional connectivity outperforms other modalities to predict behavioral phenotypes. In this study, we also transformed the phenotype measures into a latent variable representation, and used those latent variables as targets for prediction experiments. <ref type=\"figure\" coords=\"14,130.14,466.94,41.62,8.74\">Figure 2d<\/ref> and <ref type=\"figure\" coords=\"14,193.79,466.94,41.62,8.74\">Figure 3d<\/ref> illustrates that even though the first components have the highest prediction performance, the obtained performance is not higher than that obtained for the untransformed phenotype measures (<ref type=\"figure\" coords=\"14,168.37,490.85,41.56,8.74\">Figure 2b<\/ref> and <ref type=\"figure\" coords=\"14,233.22,490.85,36.03,8.74\">Figure 3b<\/ref>). One important point is to make a distinction between predictability and reliability, as a perfectly reliable phenotype might still not be predictable or, even worse, might not be related to the phenomena being studied. <ref type=\"bibr\" target=\"#b22\" coords=\"14,339.70,514.76,118.48,8.74\">Finn and Rosenberg (2021)<\/ref> illustrates this point by making an analogy between functional connectivity (FC) and barcodes. Barcodes are unique patterns, but they have no intrinsic connection to any noteworthy traits of the items they label. Therefore barcodes can have excellent accuracy for identification purposes while offering limited value in predict- ing behavior. In simpler terms, FC might be oneof-akind yet fail to provide meaningful insights (high reliability but low validity).<\/p><p coords=\"14,72.00,619.62,451.28,44.60\">The majority of SVD latent variables are needed to explain 95% of phenotype variance, but only the first few can be reliably estimated. Phenotype prediction is a challenging task, with performance often being negligible, in terms of r <hi rend=\"superscript\">2<\/hi> , if not undistinguishable from chance level. <ref type=\"bibr\" target=\"#b9\" coords=\"14,396.56,619.62,71.24,8.74\">Ooi et al. (2022)<\/ref> showed that latent variables derived from phenotypes using factor analysis could be more predictable than using the untransformed phenotypes in the HCP and ABCD datasets. We wanted to assess if this finding would replicate with a different dimensionality reduction algorithm, and generalize to other datasets.<\/p><p coords=\"14,89.71,739.17,415.55,8.74\">The present study employed SVD because it is the most efficient approach to producing lowrank data approximations. The questionnaires used to produce the phenotype measures in each study are chosen to span a range of domains of cognition. However, it is quite likely that each phenotype measure draws from more than one latent construct, leading to a complex correlation structure between them. This correlation structure - identified with SVD, PCA, or FA - allows robust identification of latent variables, and has been used to guarantee the performance of transfer learning algorithms (<ref type=\"bibr\" target=\"#b38\" coords=\"14,72.00,727.22,451.27,20.69\">He et al., 2022<\/ref>). The resulting latent variables may also be more interpretable because they are uncorrelated.<\/p><p coords=\"15,442.53,134.93,8.58,8.74\">For both datasets, the majority of the latent variables were required to account for 95% of the variance; at the same time, the first variables explain more variance than most others (<ref type=\"figure\" target=\"#fig_4\" coords=\"14,411.92,763.09,34.64,8.74\">Figure 5<\/ref>). Because of this behavior, we hypothesised that the predictability of each latent variable would be correlated with how much variance it explains. As discussed above and visible from <ref type=\"figure\" coords=\"15,351.10,87.11,36.09,8.74\">Figure 2d<\/ref>, the observed phenomenon is more complicated than that. Over the first few latent variables, there was no clear relationship between the amount of variance explained and predictability. This is particularly visible for the HCP data, where the first latent variable, which explains 16% of the variance, was not the most predictable one. At the same time, predictability decays rapidly after the first few latent variables (<ref type=\"figure\" coords=\"15,403.21,134.93,35.03,8.74\">Figure 2d<\/ref>).<\/p><p coords=\"15,72.00,197.01,451.28,152.20\">This latter finding prompted us to study the reproducibility of the loadings associated with each latent variable. To do this, we used the Gale-Shapley stable marriage algorithm (<ref type=\"bibr\" target=\"#b25\" coords=\"15,72.00,161.15,451.27,20.69\">Gale and Shapley, 1962<\/ref>), where we used the correlation to match latent phenotypes across different splits. After further investigation, we observed that, for both datasets, only the loadings for the first five components were reliably identified on 1000 repetitions (<ref type=\"figure\" target=\"#fig_5\" coords=\"15,240.36,197.01,34.20,8.74\">Figure 6<\/ref>), and reliability quickly decays for the remaining factors. We think that due to the mathematical properties of the SVD (that requires all components to be orthonormal), we see an increase of reliability in the lowvariance phenotypes again. The increase in reliability for the first components might be related to their increased predictability compared to the other latent phenotypes. Further highlighting this complex relation between predictability and reliability, we also noticed that, in the HCP dataset, some of the variables explaining the least variance are most predictable. This experiment is important as it showcases that, beyond five latent phenotypes, there would be no guarantee of finding the same latent phenotypes in different samples. If we cannot even ensure reliable splits within the same dataset, our ability to uncover relationships in outof-sample associations becomes increasingly uncertain. Our results raise an interesting question: why do latent features beyond the fifth one become unreliable, and why do they explain so little variance? One simple guess would be that starting from the fifth component, what is predominantly being captured is either noise or variance that occurs on very few subjects, as opposed to meaningful, structured information inherent in the data.<\/p><p coords=\"15,72.00,399.82,451.28,80.47\">A lowdimensional representation of phenotype variables has similar predictability to the original phe- notypes. The unreliability from the fifth latent phenotype onward prompted us to question how much information could be predicted using only the reliable latent variables. <ref type=\"figure\" coords=\"15,383.12,399.82,40.92,8.74\">Figure 2c<\/ref> and <ref type=\"figure\" coords=\"15,446.87,399.82,40.91,8.74\">Figure 3c<\/ref> demon- strate that only a few latent variables are necessary to adequately reconstruct the training set phenotype measures, and achieve similar performance on the validation set as a model trained using the original phenotype measures. This finding suggests that relations between phenotype measures that are present across many participants may be captured primarily on the first few latent variables. Therefore, SVD could serve as a denoising algorithm, providing means to work with fewer latent variables in training but still yielding as good or better prediction performance as using the original phenotype measures.<\/p><p coords=\"15,72.00,617.32,451.28,44.60\">The relationship between noise and reliability and predictive models is crucial but, while the im- portance of sample size for statistical power is widely acknowledged, the consideration of measurement reliability when estimating the required sample sizes remains an underaddressed aspect (<ref type=\"bibr\" target=\"#b45\" coords=\"15,72.00,509.72,451.28,20.69\">Zuo et al., 2019<\/ref>). Following this logic, <ref type=\"bibr\" target=\"#b26\" coords=\"15,191.49,521.68,72.27,8.74\">Gell et al. (2023)<\/ref>; <ref type=\"bibr\" target=\"#b54\" coords=\"15,271.30,521.68,99.02,8.74\">Nikolaidis et al. (2022)<\/ref> propose that focusing on the relia- bility of phenotypic measurements during target selection and choosing only those with high reliability might improve the performance of brainbehavior models. However, due to the notable variability in reliability, the proposed sample size requirements may not universally apply (<ref type=\"bibr\" target=\"#b22\" coords=\"15,408.39,557.54,96.73,8.74\">Rosenberg and Finn, 2022<\/ref>; <ref type=\"bibr\" target=\"#b9\" coords=\"15,72.00,569.50,61.23,8.74\">Chen et al., 2023<\/ref>). As a significant consequence, when the reliability of a measurement diminishes, a larger number of participants will be needed to accurately identify a correlation between two measures (<ref type=\"bibr\" target=\"#b45\" coords=\"15,77.12,593.41,52.96,8.74\">Zuo et al., 2019<\/ref>). Some studies have found that a larger sample size helps obtain a higher prediction performance, but carefully choosing reliable targets has a bigger impact on the model's performance (<ref type=\"bibr\" target=\"#b26\" coords=\"15,76.33,617.32,55.21,8.74\">Gell et al., 2023<\/ref>; <ref type=\"bibr\" target=\"#b54\" coords=\"15,153.62,617.32,80.73,8.74\">Nikolaidis et al., 2022<\/ref>). One remaining question is whether using lowrank SVD re- constructions of the phenotype measures lessens the sample sizes needed to obtain a given prediction performance. This could be tested by running resampling experiments with smaller sample sizes, but this is beyond the scope of the present paper.<\/p><p coords=\"15,89.71,763.09,8.86,8.74\">In this paper, we did not assess the reliability of the features that are important for prediction. Many works that trained brainbehavior models use a variety of interpretation techniques - e.g., feature weights or saliency maps - to analyze which brain regions were more relevant for prediction (<ref type=\"bibr\" target=\"#b22\" coords=\"15,72.00,691.35,451.28,20.69\">Finn et al., 2015<\/ref>; <ref type=\"bibr\" target=\"#b45\" coords=\"15,129.08,703.31,62.30,8.74\">Jiang et al., 2020<\/ref>; <ref type=\"bibr\" target=\"#b9\" coords=\"15,213.80,703.31,61.51,8.74\">Chen et al., 2022<\/ref>). While reliability of the prediction targets has not been the focus of some of these studies (<ref type=\"bibr\" target=\"#b22\" coords=\"15,255.58,715.26,75.89,8.74\">Finn et al., 2015;<\/ref> <ref type=\"bibr\" target=\"#b45\" coords=\"15,335.54,715.26,61.74,8.74\">Jiang et al., 2020<\/ref>; <ref type=\"bibr\" target=\"#b9\" coords=\"15,419.51,715.26,60.70,8.74\">Chen et al., 2022<\/ref>)., the feature weights of models frequently show moderate to low testretest reliability as well. Surprisingly, a linear transformation to these feature weights (i.e., Haufetransformed weights (<ref type=\"bibr\" target=\"#b37\" coords=\"15,437.43,739.17,62.79,8.74\">Haufe et al., 2014<\/ref>)) demonstrated greater reliability compared to untransformed weights (<ref type=\"bibr\" target=\"#b72\" coords=\"15,371.09,751.13,82.64,8.74\">Tian and Zalesky, 2021<\/ref>; <ref type=\"bibr\" target=\"#b9\" coords=\"15,72.00,751.13,451.28,20.69\">Chen et al., 2023<\/ref>).<\/p><\/div><div><head coords=\"16,72.00,75.16,133.50,8.74\">Limitations of the current work<\/head><p coords=\"16,72.00,242.53,451.28,32.65\">To overcome the scarcity of data, a few studies have used transfer learning to improve the performance of brainbehavior models (<ref type=\"bibr\" target=\"#b42\" coords=\"16,313.69,87.11,85.63,8.74\">Holderrieth et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b38\" coords=\"16,420.97,87.11,48.51,8.74\">He et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b11\" coords=\"16,72.00,87.11,451.28,20.69\">Chopra et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b11\" coords=\"16,123.69,99.07,61.98,8.74\">Wulan et al., 2024<\/ref>) and shown that information from large datasets with rich phenotypic data can be used to improve performance on smaller datasets. However, there are still many implementation details that need to be further investigated before being able to transfer phenotype models from large to small datasets successfully. Generalizability, the broad applicability of a model, is closely linked to the concept of transfer learning. The main difference is that while generalizability refers to the model's ability to perform well on new, unseen data, in transfer learning, a model predicting a phenotype is first trained on a large dataset and then the model is refined to improve its performance on specific smaller datasets, combining the general information learned from the larger dataset with information specific to the smaller dataset. A few studies have evaluated the generalizability of models trained on one dataset to other datasets, for a variety of brainbehavioral phenotypes, and have shown that fluid intelligence is one of the few targets for which models have shown moderate performance when tested on new datasets (<ref type=\"bibr\" target=\"#b3\" coords=\"16,78.27,230.57,49.34,8.74\">Wu et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b73\" coords=\"16,149.34,230.57,58.55,8.74\">Tong et al., 2022<\/ref>). In this study, we did not explore transfer learning, as we explored the idea shown by previous research (<ref type=\"bibr\" target=\"#b54\" coords=\"16,234.05,242.53,77.32,8.74\">Nikolaidis et al., 2022<\/ref>; <ref type=\"bibr\" target=\"#b26\" coords=\"16,332.39,242.53,52.75,8.74\">Gell et al., 2023<\/ref>) that by using more reliable prediction targets (in our case obtained from latent components), we could improve the model prediction but as we have seen the using latent phenotypes did not improve the performance.<\/p><p coords=\"16,72.00,278.89,451.28,116.33\">When preprocessing the phenotypes, we zscored all phenotypes, set values that were above and below 3 standard deviations to zeros and treated those values as missing by the imputation algorithm. This choice of how to deal with outliers could have an impact on our analysis and was one of the possible researcher degrees of freedom in our analysis. In particular, by making this choice, we are eliminating the most severe scores. A possible alternative would have been to use winsorizing instead of treating the severe scores as missing. Another limitation of our preprocessing stems from the fact that we used different processing pipelines from HCP and PNC. While for the HCP we were using the already preprocessed data for HCP, we preprocessed the data using fMRIPrep. Because of this choice, we had additional information about motion parameters for PNC and used this information to censor time points that had excessive motion, but we did not censor time points with excessive motion in HCP.<\/p><p coords=\"16,72.00,494.59,451.28,80.47\">Another limitation of the current work stems from our reliance on a ridge regression model, as this can only capture a linear relationship between the functional connectivity data used as input and the phenotype measures used as prediction targets. It is still debated if the brainbehavior relationship can be better predicted using linear, and therefore more explainable models, or benefit from the non- linear models. While <ref type=\"bibr\" target=\"#b5\" coords=\"16,165.42,446.77,126.44,8.74\">Bertolero and Bassett (2020)<\/ref> showed that deep neural networks can model simple and complex relationships between brain and behavior, <ref type=\"bibr\" target=\"#b38\" coords=\"16,326.92,458.72,73.03,8.74\">He et al. (2020)<\/ref> defended that deep neural networks and kernel regression yield similar levels of accuracy when it comes to predicting behavior and demographics through functional connectivity analysis. On the other hand, <ref type=\"bibr\" target=\"#b57\" coords=\"16,432.16,482.63,91.11,8.74\">Pervaiz et al. (2020)<\/ref> and <ref type=\"bibr\" target=\"#b67\" coords=\"16,92.90,494.59,88.75,8.74\">Schulz et al. (2020)<\/ref> showed that simple linear models perform very similarly to more complex ones. The second limitation is the use of a linear method (SVD) to derive latent variables from the phenotype measures. SVD captures covariance relationships, a linear measure of association between those measures. It is possible that there are also nonlinear relationships between the phenotypes, which could be identified with nonlinear dimensionality reduction approaches such as autoencoders. Here, we chose to use both a linear model and a linear dimensionality reduction approach to set a baseline for future analyses and facilitate comparison with previous work.<\/p><p coords=\"16,72.00,578.77,451.28,80.47\">In conclusion, we showed the importance of controlling for age and sex confounds when creating a brainbehavior model. Failure to remove them could lead to artificially inflated prediction results. Our main contribution is showing that, by reconstructing phenotype variables using the first few latent SVD variables, we could obtain a very similar performance training a model on the original variables. This suggests that most of the information about phenotype that can be identified using a linear model trained on functional connectivity data is present only in the first latent phenotypes. We suggest that future research should further explore the usage of latent variables derived from phenotypes.<\/p><note type=\"fulltext:other\" coords=\"28,14.17,45.68,550.45,749.10;29,30.66,45.68,517.53,223.93;31,72.85,177.24,449.56,413.40\">PainInterf Tscore* Pain Interference Survey Age 18+: T-score Sensory (NIH Toolbox) PercHostil Unadj* Perceived Hostility Survey: Unadjusted Emotion (NIH Toolbox) PercReject Unadj* Perceived Rejection Survey: Unadjusted Emotion (NIH Toolbox) PercStress Unadj* Perceived Stress Survey: Unadjusted Emotion (NIH Toolbox) PicSeq AgeAdj Picture Sequence Memory Test: Age-Adjusted Cognition (NIH Toolbox) PicVocab AgeAdj Picture Vocabulary Test: Age-Adjusted Cognition (NIH Toolbox) PicVocab Unadj* Picture Vocabulary Test: Unadjusted Cognition (NIH Toolbox) PMAT24 A CR* Progressive Matrices Number of Correct Responses Cognition (Penn Tests) PosAffect Unadj* Positive Affect Survey: Unadjusted Emotion (NIH Toolbox) ProcSpeed AgeAdj Pattern Comparison Processing Speed: Age-Adjusted Cognition (NIH Toolbox) PSQI Score* Pittsburgh Sleep Questionnaire Total Score Alertness ReadEng AgeAdj Oral Reading Recognition Test: Age Adjusted Cognition (NIH Toolbox) ReadEng Unadj* Oral Reading Recognition Test: Unadjusted Cognition (NIH Toolbox) Relational Task Acc* Average accuracy % during RELATIONAL task In-Scanner Task Sadness Unadj* Sadness Survey: Unadjusted Emotion (NIH Toolbox) SCPT SEN* Short Continuous Performance Test: Sensitivity Cognition (Penn Tests) SCPT SPEC* Short Continuous Performance Test: Specificity Cognition (Penn Tests) SelfEff Unadj* Self-Efficacy Survey: Unadjusted Emotion (NIH Toolbox) Social Task Perc Random* Overall % of stimuli that the subject rated as random In-Scanner Task Social Task Perc TOM* Overall % of stimuli that received a social rating In-Scanner Task Strength Unadj* Grip Strength Test: Unadjusted Motor (NIH Toolbox) Taste Unadj* Regional Taste Intensity Age 12+ Unadjusted Sensory (NIH Toolbox) VSPLOT TC* Variable Short Penn Line Orientation Test: Total Correct Cognition (Penn Tests) WM Task Acc* Accuracy across all conditions in working memory task In-Scanner Task Used phenotypes from the PNC Dataset Variable Description Category LNB MCR Number of Correct Responses to for 1-Back and Letter N-Back (LNB) 2-Back Trials LNB MRTC Mean of the Median Response Time for Correct Letter N-Back (LNB) Responses for 1-Back (TP) and for 2-Back (TP) Trials MP MP2RTCR Median Response Time for Correct Mouse Click Responses Motor Praxis (MP) PADT A Total Correct Responses for All Test Trials by genus Penn Age Differentiation (PADT) PADT PC Percent Correct Responses for All Test Trials by genus Penn Age Differentiation (PADT) PADT SAME PC Percent Correct Responses to Test Trials with Penn Age Differentiation (PADT) No Age Difference, by genus PADT T Median Response Time for All Test Trials, by genus Penn Age Differentiation (PADT) PCET ACC2 Calculated Accuracy Measure Penn Conditional Exclusion (PCET) PCET CAT Number of Categories Achieved Penn Conditional Exclusion (PCET) PCPT T FP Total of Incorrect Responses to Number Trials (TP) Penn Continuous Performance (PCPT) and Letter Trials (FP) PCPT T FPRT Median Response Time for Incorrect Responses to Penn Continuous Performance (PCPT) Number Trials (TP) and Letter Trials (TP) PCPT T TP Total of Correct Responses to Number Trials (TP) Penn Continuous Performance (PCPT) and Letter Trials (TP) PCPT T TPRT Median Response Time for Correct Responses to Number Penn Continuous Performance (PCPT) Trials (TP) and Letter Trials (TP) PEDT A Total Correct Responses for All Test Trials, by genus Penn Emotion Differentiation (PEDT) PEDT ANG PC Percent of Correct Responses for Anger Trials, by genus Penn Emotion Differentiation (PEDT) PEDT FEAR PC Percent of Correct Responses for Fear Trials, by genus Penn Emotion Differentiation (PEDT) PEDT HAP PC Percent of Correct Responses for Happy Trials, by genus Penn Emotion Differentiation (PEDT) PEDT PC Percent of Correct Responses for All Test Trials, by genus Penn Emotion Differentiation (PEDT) PEDT SAD PC Percent of Correct Responses for Sad Trials, by genus Penn Emotion Differentiation (PEDT) PEDT SAME PC Percent Correct Responses to Test Trials with Neutral Penn Emotion Differentiation (PEDT) Difference, by genus PEDT T Median Response Time for All Test Trials, by genus Penn Emotion Differentiation (PEDT) PEIT CR Total Correct Responses for All Test Trials, by genus Penn Emotion Identification (PEIT) PEIT CRT Median Response Time for Total Correct Test Trial Penn Emotion Identification (PEIT) Responses, by genus PFMT IFAC RTC Median Response Time for Total Correct Test Penn Face Memory (PFMT) Trial Responses PFMT IFAC TOT Total Correct Responses for All Test Trials Penn Face Memory (PFMT) PLOT PC Percent Correct Responses for All Test Trials, by genus Penn Line Orientation (PLOT) PLOT TC Total Correct Responses for All Test Trials, by genus Penn Line Orientation (PLOT) PLOT TCRT Median Response Time for Correct Trials, by genus Penn Line Orientation (PLOT) PMAT CR Total Correct Responses for All Test Trials, by genus Primary Mental Abilities (PMAT) PVRT CR Total Correct Responses for All Test Trials, by genus Penn Verbal Reasoning (PVRT) PVRT RTCR Median Response Time for Correct Verbal Reasoning Penn Verbal Reasoning (PVRT) Responses, by genus PVRT RTER Median Response Time for Incorrect Verbal Reasoning Penn Verbal Reasoning (PVRT) Responses, by genus PWMT KIWRD RTC Median Response Time for Total Correct Test Trial Penn Word Memory (PWMT) Responses PWMT KIWRD TOT Total Correct Responses for All Test Trials Penn Word Memory (PWMT) VOLT SVT Total Correct Responses for All Test Trial Visual Object Learning (VOLT) VOLT SVTCRT Median Response Time for Total Correct Responses Visual Object Learning (VOLT) VOLT SVTIRT Median Response Time for Incorrect Responses Visual Object Learning (VOLT) WRAT CR RAW Total Raw Score Wide Range Achievement (WRAT) WRAT CR STD Total Standard Score Wide Range Achievement (WRAT) 0.1 0.0 0.1 0.2 PADT_T PVRT_RTER MP_MP2RTCR PCPT_T_FPRT PEDT_T PCET_ACC2 PEDT_SAD_PC PLOT_TCRT PEDT_SAME_PC VOLT_SVT PEIT_CR PCET_CAT PWMT_KIWRD_RTC PADT_SAME_PC PEDT_ANG_PC PWMT_KIWRD_TOT VOLT_SVTIRT VOLT_SVTCRT PEDT_HAP_PC PVRT_RTCR PEDT_FEAR_PC PEDT_PC PFMT_IFAC_RTC LNB_MRTC LNB_MCR PEIT_CRT PEDT_A PCPT_T_TPRT PLOT_TC WRAT_CR_STD PADT_A PLOT_PC PFMT_IFAC_TOT PMAT_CR PADT_PC PCPT_T_TP PCPT_T_FP PVRT_CR WRAT_CR_RAW a <hi rend=\"subscript\">No Regression<\/hi> 0.1 0.0 0.1 0.2 PADT_T PADT_SAME_PC MP_MP2RTCR PCET_ACC2 PWMT_KIWRD_RTC PEDT_SAD_PC PCPT_T_FPRT PEDT_T PLOT_TCRT PCPT_T_TPRT PVRT_RTER VOLT_SVT PEDT_ANG_PC PEDT_SAME_PC PEIT_CR PWMT_KIWRD_TOT PCET_CAT PVRT_RTCR PEDT_PC PEIT_CRT PEDT_A VOLT_SVTIRT LNB_MRTC LNB_MCR PEDT_FEAR_PC VOLT_SVTCRT PEDT_HAP_PC PCPT_T_FP PLOT_TC PADT_A PFMT_IFAC_RTC PCPT_T_TP PADT_PC PLOT_PC PFMT_IFAC_TOT WRAT_CR_STD PMAT_CR WRAT_CR_RAW PVRT_CR b With Regression 0.1 0.0 0.1 0.2 PADT_T PADT_SAME_PC MP_MP2RTCR PCET_ACC2 PWMT_KIWRD_RTC PEDT_SAD_PC PCPT_T_FPRT PEDT_T PLOT_TCRT PCPT_T_TPRT PVRT_RTER VOLT_SVT PEDT_ANG_PC PEDT_SAME_PC PEIT_CR PWMT_KIWRD_TOT PCET_CAT PVRT_RTCR PEDT_PC PEIT_CRT PEDT_A VOLT_SVTIRT LNB_MRTC LNB_MCR PEDT_FEAR_PC VOLT_SVTCRT PEDT_HAP_PC PCPT_T_FP PLOT_TC PADT_A PFMT_IFAC_RTC PCPT_T_TP PADT_PC PLOT_PC PFMT_IFAC_TOT WRAT_CR_STD PMAT_CR WRAT_CR_RAW PVRT_CR c Reconstruction 1 2 3 4 5 all 0.1 0.0 0.1 0.2 d <hi rend=\"subscript\">Latent<\/hi><\/note><note type=\"fulltext:other\" coords=\"32,248.41,152.86,242.09,10.79\"><hi rend=\"bold\">HCP PNC<\/hi><\/note><\/div><div><head coords=\"33,72.00,75.13,395.11,8.77\" n=\"5.6\">How many latent phenotypes do we need to have an accurate prediction?<\/head><note type=\"fulltext:other\" coords=\"33,212.37,392.93,171.82,6.10\">PNC HCP<\/note><\/div><div><head coords=\"37,72.00,310.44,57.86,8.74\">Imaging data<\/head><p coords=\"37,351.15,477.82,3.87,8.74\">We have already preprocessed the HBN imaging data with the same preprocessing de- scribed in our preprint for the PNC dataset. The preprocessing of the HBN dataset was conducted using fmriprep version 21.0.2. Motion censoring was performed at the individual time point level, with points exceeding 0.2 mm framewise displacement or a derivative root mean square (DVARS) above 75 marked for censoring. Intervals of less than five points between censor points were also flagged for censoring. The six estimated headmotion parameters, their derivatives, and average signals within anatomicallyderived white matter and cerebrospinal fluid masks obtained from fmriprep, were regressed from the functional magnetic resonance imaging (fMRI) signal prior to functional connectivity (FC) computation. We gener- ated functional connectivity matrices by calculating Pearson correlations among the average time series of each brain region pair. The regions were delineated using the Schaefer 400 parcellation, which consists of 17 networks (<ref type=\"bibr\" target=\"#b31\" coords=\"37,146.14,430.00,74.63,8.74\">Schaefer et al., 2018<\/ref>). If any of the runs had more than 50% of the runs flagged as time points to be censored, we do not use that run for computing the FC. Some subjects from the HBN dataset contain more than one resting state runs, if more than one run is available for a subject, we will use an average of the computed functional connectivity. For a complete description of how the functional connectivity matrix will be computed, please refer to section 2.2.<\/p><\/div><div><head coords=\"37,72.00,497.91,48.51,8.74\">Phenotypes<\/head><p coords=\"37,72.00,617.46,451.28,20.69\">While the HBN dataset encompasses both behavioral and clinical phenotypes, our analysis focused exclusively on behavioral measures. We specifically selected cognitive phenotypes that cover constructs similar to those found in the HCP and PNC datasets. For each specific instrument, we selected the summary metric it provided, rather than individual answers or subscales, to ensure consistency with the other datasets in our analysis. Ultimately, while the original phenotypes cover behavioral, personality, and mental health domains, we curated a set of 29 behavioral scores (see section 3 for a full list). As a final check to identify problems or redundancy, we also calculated the correlation between the different phenotypes selected (<ref type=\"figure\" target=\"#fig_10\" coords=\"37,166.25,581.60,34.98,8.74\">Figure 13<\/ref>). As described below, missing phenotypes or phenotypes that are above and below 3 standard deviations will be treated as missing data and imputed. All phenotype values will be zscored to be on a similar scale and avoid scores that are higher to dominate the model prediction. For a complete description, please refer to section 2.1 and section 2.1, where we describe how the behavioral phenotypes are preprocessed for the HCP and PNC datasets.<\/p><\/div><div><head coords=\"37,72.00,655.46,77.88,8.77\">Unit of analysis<\/head><p coords=\"37,72.00,739.17,451.28,32.65\">Which units of analysis (respondents, cases, etc.) will be included or excluded in your study? Taking these inclusion and exclusion criteria into account, indicate the expected sample size of the data you'll be using for your statistical analyses. If you have a research question about a certain group you may need to exclude participants based on one or more characteristics. Be very specific when describing these characteristics so that readers will be able to redo your moves easily. Subjects were chosen if their imaging preprocessing pipeline was completed without error and if any of the runs had more than 50% of the time points flagged as points to be censured (due to the recessive motion), we do not use that run for computing the FC. The numbers described in section 6.7, describe the dataset that will be used for this confirmatory analysis. Missing phenotypes were not used as criteria for exclusion, as we imputed the missing phenotype values.<\/p><\/div><div><head coords=\"38,72.00,483.53,65.63,8.77\">Missing data<\/head><p coords=\"38,72.00,579.20,451.28,56.56\">What do you know about missing data in the dataset (i.e., overall missingness rate, information about differential dropout)? How will you deal with incomplete or missing data? Provide descriptive information, if available, on the amount of missing data for each variable you will use in the statistical analyses. Based on this information, provide a new expected sample size. Similar to the analysis described in our preprint for the HCP and PNC dataset (section 2.1 and 2.1, each phenotype measure underwent zscoring across the phenotypic measures. We identified missing values and removed outliers (i.e., variables that were above/below 3 standard deviations for that phenotype), and imputed both using the IterativeImputer function from the scikitlearn library (<ref type=\"bibr\" target=\"#b0\" coords=\"38,72.00,567.25,451.28,20.69\">Pedregosa et al., 2011<\/ref>). The main idea behind the IterativeImputer is to model each missing value in one variable as a function of all the other variables available for a subject that is present. The algorithm works iteratively in a roundrobin matter, where during each iteration, one phenotype is chosen as (y), and the remaining features are used as input to the imputation algorithm. Subjects that had no phenotypical information were excluded; however, if one phenotype was present, all the remaining values were imputed.<\/p><\/div><div><head coords=\"38,72.00,655.74,87.95,8.77\">Sampling weights<\/head><p coords=\"38,72.00,655.77,451.28,44.60\">Are there sampling weights available with this dataset? If so, are you using them or are you using your own sampling weights? Sampling weights can be useful in secondary data analysis because the sample may not be entirely representative of the population you are interested in. There are no sampling weights. Models are trained and evaluated on samples from the same population.<\/p><\/div><div><head coords=\"38,72.00,720.36,122.15,8.77\" n=\"6.9\">Knowledge of Data<\/head><p coords=\"39,72.00,519.04,451.28,68.51\">Prior Publication/Dissemination List the publications, working papers, and conference presenta- tions you have worked on that are based on the dataset you will use. For each work, list the variables you analyzed, but limit yourself to variables that are relevant to the proposed analysis. If the dataset is longitudinal, also state which wave of the dataset you analyzed. Specify the previous works for each coauthor separately. The work described in the main manuscript, in which all coauthors were involved, analysed the predictability of phenotypes from the Human Connectome Project (HCP) and the Philadel- phia Neurodevelopmental Cohort (PNC). Building on these findings, we are testing the generalizability of our results by incorporating a third dataset. Therefore, the analyses described in this preregistration will be the same as those described in our preprint (the main part of this document).<\/p><\/div><div><head coords=\"39,72.00,608.42,81.34,8.77\">Prior knowledge<\/head><p coords=\"39,72.00,608.45,451.28,44.60\">Disclose any prior knowledge you may have about the dataset that is relevant for the proposed analysis. If you do not have any prior knowledge of it, please state so. Your prior knowledge could stem from working with the data firsthand, from reading previously published research, or from codebooks. Provide prior knowledge for every author separately.<\/p><p coords=\"39,72.00,679.92,451.28,32.65\">All coauthors are familiar with the original publication provided by the HBN consortia where the recruit- ment criteria and data description are detailed (<ref type=\"bibr\" target=\"#b1\" coords=\"39,285.83,679.92,80.25,8.74\">Alexander et al., 2017<\/ref>). We have already preprocessed the neuroimaging data as described above, selected the phenotypes, and formatted the phenotypic data to be compatible with our analytical pipeline.<\/p><p coords=\"39,72.00,727.48,297.54,8.74\">Jessica Dafflon has worked with the structural MRI from the HBN.<\/p><p coords=\"39,434.50,763.09,8.86,8.74\">Dylan M. Nielson has worked with the HBN data before and published a preprint Validation of CBCL depression scores of adolescents in three independent datasets (<ref type=\"bibr\" target=\"#b79\" coords=\"39,349.33,763.09,71.89,8.74\">Zelenina et al., 2023<\/ref>).<\/p><note type=\"fulltext:other\" coords=\"40,72.00,107.49,451.28,632.15\">Test Description NIH Scores NIH7 Card Dimensional Change Card Sort Age 3+ Ageadjusted Scale Score NIH7 Flanker Flanker Inhibitory Control and Attention Age 3+ Ageadjusted Score NIH7 List List Sorting Working Memory Age 7+ Ageadjusted Score NIH7 Pattern Pattern Comparison Process Speed 7+ Ageadjusted Score WISC WISC BD Scaled Block Design Scaled Score WISC Similarities Scaled Similarities Scaled Score WISC MR Scaled Matrix Reasoning Scaled Score WISC DS Scaled Digit Span Scaled Score WISC Coding Scaled Coding Scaled Score WISC Vocab Scaled Vocabulary Scaled Score WISC FW Scaled Figure Weights Scaled Score WISC VP Scaled Visual Puzzles Scaled Score WISC PS Scaled Picture Span Scaled Score WISC SS Scaled Symbol Search Scaled Score WISC VSI VSI Composite Score WISC VC VCI Composite Score WISC FRI FRI Composite Score WISC WM WMI Composite Score WISC PSI PSI Composite Score WISC FSIQ FSIQ Composite Score WIAT WIAT Num Stnd Numerical Operations Standard Score WIAT Pseudo Stnd Pseudoword Decoding Standard Score WIAT Spell Stnd Spelling Standard Score WIAT Word Stnd Word Reading Standard Score WIAT LCRV Std Listening Comprehension Receptive Vocabulary Standard Score WIAT LCODC Stnd Listening Comprehension Oral Discourse Comprehension Standard Score WIAT LC Stnd Listening Comprehension Standard Score WIAT RC Stnd Reading Comprehension Standard Score WIAT MP Stnd Math Problem Solving Standard Score Dustin Moraczewski has interacted with the dataset through familiarity with the relevant data papers and other literature, as well as the dataset contents, and has engaged in downloading, preprocessing, quality checking, and preparing the data for collaborators but has not implemented any further analyses. Eric Earl has interacted with the dataset only to reshape the tabular phentoype data for easier ingestion into the project's analysis (Earl et al., 2023). Gabriel Loewinger has never worked with the HBN dataset before. Patrick McClure has never worked with the HBN dataset before. Adam G. Thomas has familiarity with the dataset via analysis presented in Lam et al. (2022) which has been presented at lab meetings. Francisco Pereira was involved in a separate study (Lam et al., 2022) where they used the HBN data to test a new method for creating interpretable latent variables. However, in this study, the authors have used only the clinical phenotypes from the HBN. Neither the behavior nor the imaging data which we will use were analyzed. 6.10 Analyses<\/note><\/div><div><head coords=\"40,72.00,751.10,88.83,8.77\">Statistical models<\/head><p coords=\"40,72.00,751.13,451.28,20.69;41,72.00,75.16,451.28,20.69\">For each hypothesis, describe the statistical model you will use to test the hypoth- esis. Include the type of model (e.g., ANOVA, multiple regression, SEM) and the specification of the model. Specify any interactions and posthoc analyses and remember that any test not included here must be labeled as an exploratory test in the final paper.<\/p><\/div><div><head coords=\"41,76.21,120.33,410.52,8.77\" n=\"1.\">How does controlling for age/sex confounds impact the phenotypes prediction?<\/head><p coords=\"41,88.94,156.22,434.34,56.56\">To answer this question, we will fit a ridge regression to predict phenotypes from resting state functional connectivity before and after regressing out age and sex, along with the nonlinear term age <hi rend=\"superscript\">2<\/hi> and the interaction terms age × sex and age <hi rend=\"superscript\">2<\/hi> × sex. See section 2.4 from the main manuscript for a detailed description of how we control for those covariates. The correlation between predicted and true phenotypes before and after the covariate regression will be compared along with the beta- coefficients obtained for each phenotype measure. We will use a paired ttest to ensure that the differences observed are not noise with an alpha of 0.05.<\/p><p coords=\"41,88.94,311.98,434.34,32.65\">2. How reliable are the latent phenotypes estimated with SVD across different samples? To assess the consistency of the Singular Value Decomposition (SVD) derived latent phenotypes, we will analyze how many of these latent phenotypes would replicate when the SVD is applied to two independent samples from the same population (for a detailed description, please refer to section 3.4). To do this, we will divide the phenotype dataset into two halves 1000 times and independently perform the SVD on each split. Due to the mathematical properties of the SVD, it is not guaranteed that we will get the same component order. We will use a reference SVD obtained from using the entire data and employ the Gale-Shapely stable marriage algorithm (<ref type=\"bibr\" target=\"#b25\" coords=\"41,370.91,300.03,89.26,8.74\">Gale and Shapley, 1962<\/ref>) to match each component to its counterpart in the splits (refer to the preprint section 2.7 for a more detailed description). Our cutoff for defining a reliable component will be an empirical lower 95% confidence interval on the r <hi rend=\"superscript\">2<\/hi> greater than 0.2.<\/p><p coords=\"41,76.21,348.16,447.07,20.72\">3. Can we obtain more predictable phenotypes if we use a linear transformation to latent phenotypes (SVD) on HBN?<\/p><p coords=\"41,88.94,431.88,434.34,32.65\">We will also train a ridge regression to predict the latent phenotypes (SVD latent variables derived from the phenotypes) from resting state functional connectivity. The main idea of this experiment is to see if, by compressing the phenotypes into a latent repression, we will lose any predictive information. We will evaluate the change in performance by comparing the prediction performance for the untransformed variables and those after the SVD. We motivated the selection of SVD in section 2.3 and go into detail about the SVD definition in section 5.2. We will use a paired ttest to ensure that the differences in error for the predicted and true values between the latent and phenotype populations observed are not noise with an alpha of 0.05.<\/p><p coords=\"41,88.94,527.86,434.34,56.56\">4. Is the reconstruction of latent phenotypes more predictable than using all latent phe- notypes? Similar to what we described in the main section of this manuscript (section 3.5), to evaluate if ridge regression models trained using reconstructed phenotype variables (using a range of 1 to maximum of reliable latent phenotypes, which we expect to be 5, latent components and all components) performed as well or better than one trained using the original phenotypes, we will use the Autorank library (<ref type=\"bibr\" target=\"#b40\" coords=\"41,190.06,527.86,45.46,8.74\">Herbold, 2020<\/ref>; <ref type=\"bibr\" target=\"#b16\" coords=\"41,257.68,527.86,44.68,8.74\">Demšar, 2006<\/ref>) to check if there is a significant performance between the reconstructed results. The choice of training 6 models is motivated by our exploratory analyses, where we saw that only the first five latent phenotypes in each dataset were reliable, and while most of the variance could be explained by the first two latent phenotypes, explaining 95% of the variance would require most of the latent phenotypes.<\/p><\/div><div><head coords=\"41,72.00,607.24,51.28,8.77\">Effect size<\/head><p coords=\"41,72.00,607.27,451.28,20.69\">If applicable, specify a predicted effect size or a minimum effect size of interest for all the effects tested in your statistical analyses.<\/p><p coords=\"41,76.21,654.78,447.07,32.68\">1. How does controlling for age/sex confounds impact the phenotypes prediction? The effect size (Cohen's d) we observed in HCP was 0.62 and in PNC it was 1.03. We will be conservative and use the smaller of the two effect sizes to estimate our statistical power in HBN.<\/p><p coords=\"41,76.21,690.98,447.07,32.68\">2. How reliable are the latent phenotypes estimated with SVD across different samples? Our evaluation of latent phenotype reliability is based on the lower 95% confidence interval of the intersplit r <hi rend=\"superscript\">2<\/hi> . We set a threshold of 0.2.<\/p><p coords=\"41,76.21,727.19,447.07,44.63\">3. Can we obtain more predictable phenotypes if we use a linear transformation to latent phenotypes (SVD) on HBN? The sample size for our test set in HBN will be 105 participants. With 105 participants we will have 80% power to detect an effect with a Cohen's d of 0.275.<\/p><p coords=\"43,76.21,75.13,447.07,32.68\">1. Evaluate our previous findings with a third dataset: Our major effort is to assess whether previous findings for PNC and HCP would generalize to an independent dataset. This is why we are preregistering this analysis where we reimplement the same methods on a separate dataset.<\/p><p coords=\"43,76.21,110.99,447.07,56.59\">2. Assess the reliability of the latent phenotypes: As we mentioned above (Analysis, statistical models), there is no guarantee that if we repeat the SVD on different splits of the data, we would obtain the same results. Therefore, we repeated the analysis on 1,000 different splits and assessed how reliably we could identify the components on different splits (See section Analysis, statistical methods or our preprint for a more detailed description).<\/p><p coords=\"43,88.94,194.71,434.34,20.69\">3. Resampling within datasets: All of our reported results have been conducted using bootstrapping (i.e., we repeated our analysis 100 times with different training datasets resampled from the original one - see section 2.5 for a detailed description). We use these bootstraps to reduce the variance of our predictive performance estimates.<\/p><\/div><div><head coords=\"43,72.00,236.52,103.68,8.77\">Exploratory analysis<\/head><p coords=\"43,72.00,236.55,451.28,32.65\">If you plan to explore your dataset to look for unexpected differences or rela- tionships, describe those tests here. If reported, add them to the final paper under a heading that clearly differentiates this exploratory part of your study from the confirmatory part.<\/p><p coords=\"43,88.94,352.12,434.34,32.65\">- How predictable are phenotypes from functional connective in HBN, and how do they compare to the predictability of the other datasets we analyzed? To answer this question we will fit a ridge regression to try to predict phenotypes from resting state functional connectivity. We will check if the obtained predictions are within the same range (r = [0, 0.4]) as those obtained for the other two datasets. For a detailed description of how the ridge regression model will be trained and which variables will be used as input, please refer to section 2.5 of the main manuscript, as the same model architecture (retrained for the HBN dataset) and preprocessing used for HCP and PNC will be used for the new dataset<\/p><\/div><figure coords=\"5,72.00,194.49,451.28,51.73\" xml:id=\"fig_0\"><head coords=\"5,72.00,194.49,27.89,7.89\">Fig. 1.<\/head><label coords=\"5,72.00,194.49,27.89,7.89\">Fig. 1.<\/label><figDesc coords=\"5,72.00,194.51,451.28,51.70\">Schematic overview of how the data matrix is constructed. First, the brain activity is parcellated using an atlas of choice (here we used the Schaefer 400 parcellation). The functional connectivity matrix is created by computing the Pearson correlation between the average restingstate fMRI time series in each pair of regions. Because the FC matrix is symmetric between its upper and lower triangular entries, we flatten only the lower triangular entries of the functional connectivity matrix.<\/figDesc><graphic coords=\"5,72.00,72.00,451.28,96.76\" type=\"image\"/><\/figure><figure coords=\"8,72.00,585.42,451.28,106.52\" xml:id=\"fig_1\"><head coords=\"8,72.00,585.42,27.89,7.89\">Fig. 2.<\/head><label coords=\"8,72.00,585.42,27.89,7.89\">Fig. 2.<\/label><figDesc coords=\"8,72.00,585.45,451.28,106.49\">Predictability of phenotype variables in the HCP validation set before regressing out confounds (a), after confound removal (b), reconstructed using only a subset of the latent phenotypes (c), and of the latent phenotypes (d). Predictability is quantified as the correlation between true phenotypes and prediction from functional connectivity data. Panel c shows the correlation of the predicted phenotypes with true values when the model was trained with a subset of latent phenotypes (1, 2, 3, 4, 5 and all, represented by the different shades of green). The shaded regions represent the standard deviation across resamplings. The phenotypes (yaxis) are ordered by the prediction performance, with the exception of (d), which is ordered by the variance explained by the latent phenotypes. (a) Before regressing out, the phenotypes with the best performance is \"Strength unadjusted\"; after regressing age and sex, cognitive phenotypes have the best performance. In addition, using latent phenotypes (d) or untransformed phenotypes (b) does not impact the performance substantially.<\/figDesc><\/figure><figure coords=\"9,72.00,607.59,451.28,62.68\" xml:id=\"fig_2\"><head coords=\"9,72.00,607.59,27.89,7.89\">Fig. 3.<\/head><label coords=\"9,72.00,607.59,27.89,7.89\">Fig. 3.<\/label><figDesc coords=\"9,72.00,607.62,451.28,62.66\">Predictability of phenotype variables in the PNC validation set, before regressing out confounds (a), after confound removal (b), reconstructed using only a subset of the latent phenotypes (c), and of the latent phenotypes (d). Predictability is determined by the correlation between actual phenotypes and predictions from functional connectivity. The shaded regions represent the standard deviation across resamplings. Similarly to Figure 2, the correlation is higher before regressing out the confounds (a) than in the remaining plots (bd). As HCP and PNC have different prediction ranges, the xaxes here are different than in Figure 2<\/figDesc><\/figure><figure coords=\"10,72.00,619.23,451.28,29.81\" xml:id=\"fig_3\"><head coords=\"10,72.00,619.23,27.89,7.89\">Fig. 4.<\/head><label coords=\"10,72.00,619.23,27.89,7.89\">Fig. 4.<\/label><figDesc coords=\"10,72.00,619.25,451.28,29.78\">Betaweights of the linear regression used to regress out age, sex, and their quadratic interactions from HCP (a) and PNC (b) over the repetions. (a) Dotted lines include pairs of phenotypes included in the analysis that were both Unadjusted and Ageadjusted (AgeAdj ).<\/figDesc><\/figure><figure coords=\"11,72.00,674.46,451.28,73.64\" xml:id=\"fig_4\"><head coords=\"11,72.00,674.46,27.89,7.89\">Fig. 5.<\/head><label coords=\"11,72.00,674.46,27.89,7.89\">Fig. 5.<\/label><figDesc coords=\"11,72.00,674.49,451.28,73.62\">Explained variance for each of the latent phenotype variables obtained after applying an SVD to the behavioral variables from HCP (green, left) and PNC (blue, right). In this experiment, the SVD was computed using the training and the validation data. The bar graphs show the variance explained by each latent variable, while the line plots show the cumulative variance explained. For both datasets, a large proportion of the variance is explained by the first two latent phenotypes; however, most latent phenotypes are needed to reach 95% of the variance, as represented by the dashed line in the figure. Note that the xaxis for these two plots are different as HCP has 83 phenotypes and PNC 39.<\/figDesc><\/figure><figure coords=\"12,72.00,486.09,451.28,29.81\" xml:id=\"fig_5\"><head coords=\"12,72.00,486.09,27.89,7.89\">Fig. 6.<\/head><label coords=\"12,72.00,486.09,27.89,7.89\">Fig. 6.<\/label><figDesc coords=\"12,72.00,486.12,451.28,29.78\">Latent phenotypes reliability for both datasets HCP (in green; left) and PNC (in blue; right). The loadings of the first 5 SVD components were reliably identified within different splits using the Gale-Shapley stable marriage algorithm. The shaded area represents the 95% confidence intervals.<\/figDesc><graphic coords=\"12,72.00,234.57,451.26,225.79\" type=\"image\"/><graphic coords=\"12,72.00,234.57,451.26,225.79\" type=\"image\"/><\/figure><figure coords=\"31,72.00,618.30,451.28,40.77\" xml:id=\"fig_6\"><head coords=\"31,72.00,618.30,27.89,7.89\">Fig. 9.<\/head><label coords=\"31,72.00,618.30,27.89,7.89\">Fig. 9.<\/label><figDesc coords=\"31,72.00,618.33,451.28,40.74\">Predictability of phenotype variables in the validation set, quantified by the coefficient of determination (r <hi rend=\"superscript\">2<\/hi> by correlation between predicted and true values as in Figure 3) between predictions and true values, for PNC before regressing the covariates (a), after regression (b), reconstruction (c), and of the latent phenotypes (d). The shaded regions represent the standard deviation across resamplings.<\/figDesc><\/figure><figure coords=\"32,72.00,652.91,451.28,40.77\" xml:id=\"fig_7\"><head coords=\"32,72.00,652.91,33.19,7.89\">Fig. 10.<\/head><label coords=\"32,72.00,652.91,33.19,7.89\">Fig. 10.<\/label><figDesc coords=\"32,72.00,652.94,451.28,40.74\">Betaweights of the linear regression used to regress out age, sex, and their quadratic interactions from HCP (a) PNC (b). (a) Dotted lines include pairs of phenotypes that were both Unadjusted and Ageadjusted (AgeAdj ). These results are the same as those reported in Figure 4 but values, where the mean is above ± 0.1, are annotated in the plot. Each annotated entry corresponds to the mean (std) over the 100 repetitions.<\/figDesc><\/figure><figure coords=\"33,72.00,310.98,451.28,18.85\" xml:id=\"fig_8\"><head coords=\"33,72.00,310.98,33.19,7.89\">Fig. 11.<\/head><label coords=\"33,72.00,310.98,33.19,7.89\">Fig. 11.<\/label><figDesc coords=\"33,72.00,311.00,451.28,18.82\">Marriage results using the intersplit correlation. In contrast to the plot in the main text, where we report the r <hi rend=\"superscript\">2<\/hi> , here we report the intersplit correlation.<\/figDesc><graphic coords=\"33,115.59,114.55,361.00,181.66\" type=\"image\"/><graphic coords=\"33,115.59,114.55,361.00,181.66\" type=\"image\"/><\/figure><figure coords=\"33,72.00,593.02,451.28,29.81;37,72.00,75.16,451.28,223.93\" xml:id=\"fig_9\"><head coords=\"33,72.00,593.02,33.19,7.89\">Fig. 12.<\/head><label coords=\"33,72.00,593.02,33.19,7.89\">Fig. 12.<\/label><figDesc coords=\"33,72.00,593.05,451.28,29.78;37,72.00,75.16,451.28,223.93\">Critical difference diagrams for HCP (left) and PNC (right). For the HCP data, the posthoc Tukey HSD showed that using just one latent phenotype had a significantly worse performance than all other groups. There is, however, no significant difference in using all or a subset of latent phenotypes for the PNC dataset on exploratory factor analysis (EFA) or confirmatory factor analysis (CFA), also specify the relevant details (EFA: rotation, how the number of factors will be determined, how best fit will be selected, CFA: how loadings will be specified, how fit will be assessed, which residuals variance terms will be correlated). If you are using any categorical variables, state how you will code them in the statistical analyses. We will use a subset of the Healthy Brain Network (HBN) dataset, comprising 895 subjects. The dataset consists of a training set with 672 individuals (386 males and 286 females) with an average age of 12.40 ± 3.60 years, and a separate test set containing 105 subjects (66 males and 39 females) with an average age of 12.32 ± 3.60 years, and a holdout set containing 114 subjects (67 males and 47 females) with an average age of 12.52 ± 3.76 years. Subjects were assigned to the training, test, and holdout sets in a stratified sampling procedure. Subjects were sorted by age and sex at birth, and randomly within each sex. They were then assigned in a proportional roundrobin fashion to training, test, and holdout datasets. Although the HBN dataset contains 11 diagnostic labels, we opted not to use this information for splitting the dataset, as some conditions are represented by very few subjects. Additionally, incorporating extra criteria for comorbidity would have been necessary, complicating the dataset division process. Also, note that according to the preprocessing notation we adopted for all datasets, we encoded female as 1 and male as 2; however, when regressing out the covariates, we encoded male as 1 and female as 0. A list with the subject IDs for the train, test, and holdout dataset will be provided on the gitrepo together with the code for the analyses (https://github.com/JessyD/brainphenotypes) and on the OSF description of this project.<\/figDesc><graphic coords=\"33,116.60,402.23,186.66,168.59\" type=\"image\"/><graphic coords=\"33,294.55,402.23,182.04,161.76\" type=\"image\"/><\/figure><figure coords=\"38,99.26,450.97,396.75,7.89\" xml:id=\"fig_10\"><head coords=\"38,99.26,450.97,33.19,7.89\">Fig. 13.<\/head><label coords=\"38,99.26,450.97,33.19,7.89\">Fig. 13.<\/label><figDesc coords=\"38,135.53,450.99,360.49,7.86\">Pairwise correlation between all the HBN phenotypes that we will include in our analysis<\/figDesc><graphic coords=\"38,72.00,72.00,451.28,353.24\" type=\"image\"/><graphic coords=\"38,72.00,72.00,451.28,353.24\" type=\"image\"/><\/figure><figure coords=\"39,72.00,463.16,451.28,29.81\" xml:id=\"fig_11\"><head coords=\"39,72.00,463.16,33.19,7.89\">Fig. 14.<\/head><label coords=\"39,72.00,463.16,33.19,7.89\">Fig. 14.<\/label><figDesc coords=\"39,72.00,463.19,451.28,29.78\">Pairwise correlation between all the HBN phenotypes. This plot includes some of the variables that we defined as redundant as they include the same information, just slightly modified by any type of normalisation (percentile, scale, sum)<\/figDesc><graphic coords=\"39,72.00,72.00,451.27,365.43\" type=\"image\"/><graphic coords=\"39,72.00,72.00,451.27,365.43\" type=\"image\"/><\/figure><figure type=\"table\" coords=\"40,72.00,72.57,451.28,18.85\" xml:id=\"tab_0\"><head coords=\"40,72.00,72.57,37.47,7.89\">Table 3.<\/head><label coords=\"40,72.00,72.57,37.47,7.89\">Table 3.<\/label><figDesc coords=\"40,72.00,72.60,451.28,18.82\">This table lists the phenotype variables from the Healthy Brain Network (HBN) dataset that will be utilized for analysis. The variables are ordered by the instrument they belong to, marked in bold.<\/figDesc><\/figure><\/body><back><div type=\"acknowledgement\"><head coords=\"16,72.00,676.91,80.48,8.74\">Acknowledgements<\/head><p coords=\"16,72.00,676.91,451.28,44.60\">This research was supported by the National Institute of Mental Health Intramu- ral Research Program: ZIC-MH002968 (Dylan Nielson, Gabriel Loewinger, Patrick McClure, Francisco Pereira) and ZIC-MH002960 (Jessica Dafflon, Eric Earl, Dustin Moraczewski, Adam Thomas). This research utilized the computational resources of the NIH HPC Biowulf cluster (http://hpc.nih.gov).<\/p><\/div><div type=\"annex\"><note type=\"fulltext:other\" coords=\"2,74.74,740.08,448.54,31.55;3,74.74,762.00,210.99,9.63;16,72.00,739.17,375.79,32.65;17,72.00,75.16,295.95,68.51\"><hi rend=\"superscript\">1<\/hi> While not confounds in the strict definition of confounding from the causal inference literature (Hernan and Robins, 2023), we refer to inflation of phenotype prediction by age and sex as confounding in this paper to reflect the common usage in the machine learning field. <hi rend=\"superscript\">4<\/hi> https://github.com/nimhdsst/datasetphenotypes Authorship contribution statement Each author contributed as follows: JD: data curation, design the study, analyzed the data, contributed to the manuscript DMN: design the study, analyzed the data, contributed to the manuscript DM: design the study, data curation, contributed to the manuscript EE: data curation, contributed to the manuscript GL: methodology feedback, contributed to the manuscript AGT: design the study, contributed to the manuscript PM: design the study, contributed to the manuscript FP: data curation, design the study, contributed to the manuscript<\/note><div><head coords=\"17,72.00,158.84,115.04,8.74\">Data and Code availability<\/head><p coords=\"17,72.00,158.84,451.28,44.60\">All code is available at https://github.com/JessyD/brainphenotypes. There the user can also find the lists of participants' IDs and behavior scores utilized for both datasets. Both PNC and HCP are publicly available and can be obtained after acceptance of their respective data agreement.<\/p><\/div><div><head coords=\"22,72.00,692.58,77.56,10.52\" n=\"5\">Appendix<\/head><\/div><div><head coords=\"22,72.00,718.54,297.92,8.77\" n=\"5.1\">Additional details on fmriprep preprocessing pipeline<\/head><p coords=\"22,239.10,763.09,96.49,8.74\">Results included in this manuscript come from preprocessing performed using fMRIPrep 21.0.2 (<ref type=\"bibr\" target=\"#b18\" coords=\"22,72.00,739.17,451.27,20.69\">Esteban et al. (2018b)<\/ref>; <ref type=\"bibr\" target=\"#b18\" coords=\"22,136.20,751.13,94.28,8.74\">Esteban et al. (2018a)<\/ref>; RRID:SCR 016216), which is based on Nipype 1.6.1 (<ref type=\"bibr\" target=\"#b18\" coords=\"22,72.00,751.13,451.28,20.69\">Gorgolewski et al. (2011)<\/ref>; <ref type=\"bibr\" target=\"#b18\" coords=\"22,131.22,763.09,107.88,8.74\">Gorgolewski et al. (2018)<\/ref>; RRID:SCR 002502).<\/p><\/div><div><head coords=\"23,72.00,75.13,228.49,8.77\">Preprocessing of B0 inhomogeneity mappings<\/head><p coords=\"23,88.94,314.26,434.34,20.69\">A total of 1 fieldmaps were found available within the input BIDS structure. A B0 nonuniformity map (or fieldmap) was estimated from the phasedrift map(s) measure with two consecutive GRE (gradientrecalled echo) acquisitions. The corresponding phasemap(s) were phaseunwrapped with prelude (FSL 6.0.5.1:57b01774). A total of 1 T1-weighted (T1w) images were found within the input BIDS dataset. The T1-weighted (T1w) image was cor- rected for intensity nonuniformity (INU) with N4BiasFieldCorrection (<ref type=\"bibr\" target=\"#b74\" coords=\"23,424.19,134.93,76.94,8.74\">Tustison et al., 2010<\/ref>), distributed with ANTs 2.3.3 (<ref type=\"bibr\" target=\"#b2\" coords=\"23,223.39,146.89,67.33,8.74\">Avants et al., 2008<\/ref>, RRID:SCR 004757), and used as T1wreference throughout the workflow. The T1wreference was then skullstripped with a Nipype implementa- tion of the antsBrainExtraction.sh workflow (from ANTs), using OASIS30ANTs as target tem- plate. Brain tissue segmentation of cerebrospinal fluid (CSF), whitematter (WM) and graymatter (GM) was performed on the brainextracted T1w using fast <ref type=\"bibr\" target=\"#b10\" coords=\"23,366.91,194.71,84.97,8.74\">Zhang et al. (2001)<\/ref>. Brain surfaces were reconstructed using reconall (FreeSurfer 6.0.1, RRID:SCR 001847, <ref type=\"bibr\" target=\"#b15\" coords=\"23,422.88,206.66,58.10,8.74\">Dale et al., 1999<\/ref>), and the brain mask estimated previously was refined with a custom variation of the method to recon- cile ANTsderived and FreeSurferderived segmentations of the cortical graymatter of Mindboggle (<ref type=\"bibr\" target=\"#b0\" coords=\"23,94.78,242.53,145.05,8.74\">RRID:SCR 002438, Klein et al., 2017<\/ref>). Volumebased spatial normalization to two standard spaces (MNI152NLin2009cAsym, MNI152NLin6Asym) was performed through nonlinear registration with antsRegistration (ANTs 2.3.3), using brainextracted versions of both T1w reference and the T1w template. The following templates were selected for spatial normalization: ICBM 152 Nonlinear Asymmetrical template version 2009c [<ref type=\"bibr\" target=\"#b24\" coords=\"23,263.92,290.35,81.61,8.74\">Fonov et al. (2009)<\/ref>, RRID:SCR 008796; TemplateFlow ID: MNI152NLin2009cAsym], FSL's MNI ICBM 152 nonlinear 6th Generation Asymmetric Average Brain Stereotaxic Registration Model [<ref type=\"bibr\" target=\"#b21\" coords=\"23,262.18,314.26,82.40,8.74\">Evans et al. (2012)<\/ref>, RRID:SCR 002823; TemplateFlow ID: MNI152NLin6Asym].<\/p><\/div><div><head coords=\"23,72.00,344.62,150.28,8.77\">Functional data preprocessing<\/head><p coords=\"24,88.94,278.40,434.33,20.97\">For each of the 3 BOLD runs found per subject (across all tasks and sessions), the following preprocessing was performed. First, a reference volume and its skullstripped version were generated using a custom methodology of fMRIPrep. Headmotion parameters with re- spect to the BOLD reference (transformation matrices, and six corresponding rotation and translation parameters) are estimated before any spatiotemporal filtering using mcflirt (FSL 6.0.5.1:57b01774, <ref type=\"bibr\" target=\"#b28\" coords=\"23,88.94,404.43,79.27,8.74\">Jenkinson et al., 2002<\/ref>). BOLD runs were slicetime corrected to 1.47s (0.5 of slice acquisition range 0s-2.94s) using 3dTshift from AFNI (<ref type=\"bibr\" target=\"#b13\" coords=\"23,260.30,416.38,72.83,8.74\">Cox and Hyde, 1997<\/ref>, RRID:SCR 005927). The BOLD time- series (including slicetiming correction when applied) were resampled onto their original, native space by applying the transforms to correct for headmotion. These resampled BOLD timeseries will be referred to as preprocessed BOLD in original space, or just preprocessed BOLD. The BOLD reference was then coregistered to the T1w reference using bbregister (FreeSurfer) which imple- ments boundarybased registration (<ref type=\"bibr\" target=\"#b35\" coords=\"23,251.85,476.16,86.44,8.74\">Greve and Fischl, 2009<\/ref>). Coregistration was configured with six degrees of freedom. Several confounding timeseries were calculated based on the preprocessed BOLD: framewise displacement (FD), DVARS and three regionwise global signals. FD was com- puted using two formulations following Power (absolute sum of relative motions, <ref type=\"bibr\" target=\"#b59\" coords=\"23,437.91,512.03,80.86,8.74\">Power et al. (2014)<\/ref>) and Jenkinson (relative root mean square displacement between affines, <ref type=\"bibr\" target=\"#b28\" coords=\"23,401.17,523.98,96.47,8.74\">Jenkinson et al. (2002)<\/ref>). FD and DVARS are calculated for each functional run, both using their implementations in Nipype (fol- lowing the definitions by <ref type=\"bibr\" target=\"#b59\" coords=\"23,198.82,547.89,62.00,8.74\">Power et al., 2014<\/ref>). The three global signals are extracted within the CSF, the WM, and the wholebrain masks. Additionally, a set of physiological regressors were extracted to allow for componentbased noise correction (<ref type=\"bibr\" target=\"#b0\" coords=\"23,301.85,571.80,119.95,8.74\">CompCor, Behzadi et al., 2007<\/ref>). Principal compo- nents are estimated after highpass filtering the preprocessed BOLD timeseries (using a discrete cosine filter with 128s cutoff) for the two CompCor variants: temporal (tCompCor) and anatomical (aCompCor). tCompCor components are then calculated from the top 2% variable voxels within the brain mask. For aCompCor, three probabilistic masks (CSF, WM and combined CSF+WM) are generated in anatomical space. The implementation differs from that of Behzadi et al. in that instead of eroding the masks by 2 pixels on BOLD space, the aCompCor masks are subtracted a mask of pixels that likely contain a volume fraction of GM. This mask is obtained by dilating a GM mask extracted from the FreeSurfer's aseg segmentation, and it ensures components are not extracted from voxels containing a minimal fraction of GM. Finally, these masks are resampled into BOLD space and binarized by thresholding at 0.99 (as in the original implementation). Components are also calculated separately within the WM and CSF masks. For each CompCor decomposition, the k components with the largest singular values are retained, such that the retained components' time series are sufficient to explain 50 percent of variance across the nuisance mask (CSF, WM, combined, or temporal). The remaining components are dropped from consideration. The headmotion esti- mates calculated in the correction step were also placed within the corresponding confounds file. The confound time series derived from head motion estimates and global signals were expanded with the inclusion of temporal derivatives and quadratic terms for each (<ref type=\"bibr\" target=\"#b26\" coords=\"24,371.04,75.16,95.19,8.74\">Satterthwaite et al., 2013<\/ref>). Frames that exceeded a threshold of 0.5 mm FD or 1.5 standardised DVARS were annotated as motion out- liers. The BOLD timeseries were resampled into standard space, generating a preprocessed BOLD run in MNI152NLin2009cAsym space. First, a reference volume and its skullstripped version were generated using a custom methodology of fMRIPrep. The BOLD timeseries were resampled onto the following surfaces (FreeSurfer reconstruction nomenclature): fsaverage6, fsaverage. Automatic re- moval of motion artifacts using independent component analysis (<ref type=\"bibr\" target=\"#b60\" coords=\"24,377.19,146.89,127.04,8.74\">ICA-AROMA, Pruim et al., 2015<\/ref>) was performed on the preprocessed BOLD on MNI space timeseries after removal of nonsteady state volumes and spatial smoothing with an isotropic, Gaussian kernel of 6mm FWHM (fullwidth halfmaximum). Corresponding \"nonaggresively\" denoised runs were produced after such smooth- ing. Additionally, the \"aggressive\" noiseregressors were collected and placed in the corresponding confounds file. Grayordinates files (<ref type=\"bibr\" target=\"#b3\" coords=\"24,242.41,206.66,66.36,8.74\">Glasser et al., 2013b<\/ref>) containing 91k samples were also generated using the highestresolution fsaverage as intermediate standardized surface space. All resamplings can be performed with a single interpolation step by composing all the pertinent transformations (i.e. headmotion transform matrices, susceptibility distortion correction when available, and co- registrations to anatomical and output spaces). Gridded (volumetric) resamplings were performed using antsApplyTransforms (ANTs), configured with Lanczos interpolation to minimize the smooth- ing effects of other kernels (<ref type=\"bibr\" target=\"#b51\" coords=\"24,209.37,278.40,44.00,8.74\">Lanczos, 1964<\/ref>). Nongridded (surface) resamplings were performed using mri vol2surf (FreeSurfer).<\/p><p coords=\"24,72.00,313.24,451.28,32.65\">Many internal operations of fMRIPrep use Nilearn 0.8.1 (<ref type=\"bibr\" target=\"#b0\" coords=\"24,339.06,313.24,74.21,8.74\">Abraham et al., 2014<\/ref>, RRID:SCR 001362), mostly within the functional processing workflow. For more details of the pipeline, see the section corre- sponding to workflows in fMRIPrep's documentation.<\/p><\/div><div><head coords=\"24,72.00,368.22,214.08,8.77\" n=\"5.2\">Singular Value Decomposition (SVD)<\/head><p coords=\"24,72.00,389.35,451.28,89.68\">Definition Given a n × d data matrix X, the SVD of X is X = U SV <hi rend=\"superscript\">′<\/hi> where U is n × k, S is k × k, and V is d × k, for a given number of latent variables k. The matrices U and V are called the left and right singular vector matrices (the columns are the singular vectors), and S is the singular value matrix (the diagonal contains the singular values). The matrices U , S, and V have various useful properties:<\/p><p coords=\"24,78.23,491.16,397.73,8.77\">- U and V are orthonormal: their columns have norm 1, and are orthogonal to each other.<\/p><p coords=\"24,78.23,503.36,445.05,20.72\">- As orthonormal matrices, U and V can be viewed as bases for the spaces spanned by columns or rows of X, respectively, and where coordinates for X would be SV <hi rend=\"superscript\">′<\/hi> or U S.<\/p><p coords=\"24,78.23,527.51,332.47,8.77\">- S is a diagonal matrix, with different values in each entry of the diagonal.<\/p><p coords=\"24,78.23,539.71,445.05,20.72\">- k can only be as large as min(n, d); if X is of rank lower than that - which can happen if columns or rows are linearly dependent - it can be smaller.<\/p><\/div><div><head coords=\"24,72.00,582.76,182.15,8.77\">Dimensionality reduction with SVD<\/head><p coords=\"24,72.00,582.79,451.28,44.60\">In the dimensionality terminology used in the paper, U S is the latent variable matrix, and V <hi rend=\"superscript\">′<\/hi> is the mixing matrix. The variables in the lowdimensional space are uncorrelated, which makes them suitable for various applications (e.g., visualization, and preprocessing for other methods that assume uncorrelated variables).<\/p><p coords=\"24,72.00,679.16,451.27,21.61\">In addition, the matrix V can be used both to convert X (or other examples) in the ddimensional space into the kdimensional space, as well as convert any examples in the lowdimensional space back into the ddimensional space by multiplying them by V <hi rend=\"superscript\">′<\/hi> . <ref type=\"figure\" target=\"#fig_12\" coords=\"24,86.94,679.16,35.84,8.74\">Figure 7<\/ref> (top) shows how each individual entry x <hi rend=\"subscript\">ij<\/hi> in matrix X is reconstructable as a multiplication of the i <hi rend=\"superscript\">th<\/hi> row of U (u <hi rend=\"subscript\">i,:<\/hi> ), scaled by the entries in the diagonal of S, and by the j <hi rend=\"superscript\">th<\/hi> column of V <hi rend=\"superscript\">′<\/hi> .<\/p><p coords=\"26,72.00,75.13,451.28,33.59\">An essential step to take into consideration before applying SVD is normalization as (1) it ensures scaleinvariance in the SVD results, preventing largerscale variables from dominating the analysis and distorting the interpretation of relationships between variables; (2) without normalization, it becomes challenging to understand the relative importance and contributions of variables due to varying scales, making the interpretation less intuitive; (3) it enhances the numerical stability of SVD computations, reducing the risk of numerical errors that can arise when data scales vary widely. Relationship between SVD and the data matrix SVD provides the best approximation of the matrix X at any specified rank (i.e., one can take the full SVD and expand it to show that it reconstructs X as a sum of k rank 1 matrices, in other words, R <hi rend=\"subscript\">1<\/hi> , . . . , R <hi rend=\"subscript\">k<\/hi> :<\/p><formula coords=\"26,219.89,120.99,154.83,25.56\">X = R <hi rend=\"subscript\">1<\/hi> + . . . + R <hi rend=\"subscript\">k<\/hi> = U <hi rend=\"subscript\">:,1<\/hi> S <hi rend=\"subscript\">1,1<\/hi> V <hi rend=\"superscript\">′<\/hi> <hi rend=\"subscript\">:,1<\/hi> + . . . + U <hi rend=\"subscript\">:,k<\/hi> S <hi rend=\"subscript\">kk<\/hi> V <hi rend=\"superscript\">′<\/hi> :,k<\/formula><p coords=\"26,72.00,157.85,451.28,32.65\">as shown in <ref type=\"figure\" target=\"#fig_12\" coords=\"26,139.80,157.85,36.02,8.74\">Figure 7<\/ref> (bottom)). Each of these matrices explains some of the variance in X. If we sort the dimensions of the SVD from those that explain the most to those that explain the least, adding k matrices will yield the best rank k approximation of X, in terms of minimizing squared error.<\/p><note type=\"fulltext:other\" coords=\"25,70.06,263.08,396.88,325.88\">1 ! <hi rend=\"subscript\">:,:<\/hi> \" <hi rend=\"subscript\">#,$<\/hi> # $ % &amp;′ ( <hi rend=\"subscript\">:,%<\/hi> ( <hi rend=\"subscript\">:,&amp;<\/hi> )′ <hi rend=\"subscript\">:,%<\/hi> )′ <hi rend=\"subscript\">:,&amp;<\/hi> ! <hi rend=\"subscript\">%,%<\/hi> ! <hi rend=\"subscript\">&amp;,&amp;<\/hi> ( <hi rend=\"subscript\">#,:<\/hi> )′ <hi rend=\"subscript\">:,$<\/hi> = = + ... #",
    "support_1": true,
    "support_3": true,
    "support_4": false,
    "support_5": true,
    "support_6": false,
    "support_7": false,
    "support_8": false,
    "support_9": false,
    "support_10": false,
    "developed_1": false,
    "received_1": false,
    "received_2": false,
    "recipient_1": false,
    "authors_1": false,
    "authors_2": false,
    "thank_1": false,
    "thank_2": false,
    "fund_1": false,
    "fund_2": false,
    "fund_3": false,
    "supported_1": false,
    "financial_1": false,
    "financial_2": false,
    "financial_3": false,
    "grant_1": false,
    "french_1": false,
    "common_1": false,
    "common_2": false,
    "common_3": false,
    "common_4": false,
    "common_5": false,
    "acknow_1": false,
    "disclosure_1": false,
    "disclosure_2": false,
    "is_register_pred": false,
    "register_text": "",
    "is_relevant": true,
    "is_method": false
  }
]
